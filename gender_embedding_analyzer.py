"""
æ€§åˆ«å’ŒèŒä¸šè¯çš„embeddingåˆ†æå™¨

åŠŸèƒ½ï¼š
1. åŠ è½½å·²è®­ç»ƒçš„Word2Vecæ¨¡å‹
2. è®¡ç®—èŒä¸šè¯ä¸æ€§åˆ«è¯çš„å…³è”åº¦ï¼ˆåˆ†åˆ«è®¡ç®—ä¸ç”·æ€§è¯ã€å¥³æ€§è¯çš„ç›¸ä¼¼åº¦ï¼‰
3. æ¯”è¾ƒä¸åŒçœä»½æ¨¡å‹çš„å·®å¼‚
4. ç”Ÿæˆåˆ†ææŠ¥å‘Šå’Œå¯è§†åŒ–æ•°æ®

è¾“å…¥ï¼šembedding_models/{year}/ ä¸‹çš„æ¨¡å‹æ–‡ä»¶
è¾“å‡ºï¼šembedding_analysis/{year}/ ä¸‹çš„åˆ†æç»“æœ
"""

import os
import pandas as pd
import numpy as np
from gensim.models import Word2Vec
import fire
from sklearn.preprocessing import normalize
import warnings
import json
import glob

warnings.filterwarnings("ignore")

MODEL_DIR = "embedding_models"
OUTPUT_DIR = "embedding_analysis"

# ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
os.makedirs(OUTPUT_DIR, exist_ok=True)

# æ€§åˆ«è¯è¡¨ï¼ˆæ‰©å±•ç‰ˆï¼‰
GENDER_WORDS = {
    "male": [
        # ä»£è¯
        "ä»–",
        "ä»–ä»¬",
        "ä»–çš„",
        # åŸºç¡€æ€§åˆ«è¯
        "ç”·",
        "ç”·äºº",
        "ç”·æ€§",
        "ç”·å­",
        "ç”·ç”Ÿ",
        "ç”·å­©",
        # ç§°è°“
        "å…ˆç”Ÿ",
        "å¸…å“¥",
        "å°ä¼™",
        "å°ä¼™å­",
        "å“¥",
        "å…„å¼Ÿ",
        "çˆ·ä»¬",
        # å®¶åº­è§’è‰²
        "çˆ¶äº²",
        "çˆ¸çˆ¸",
        "çˆ¸",
        "å„¿å­",
        "ä¸ˆå¤«",
        "è€å…¬",
        "ç”·å‹",
        "ç”·æœ‹å‹",
    ],
    "female": [
        # ä»£è¯
        "å¥¹",
        "å¥¹ä»¬",
        "å¥¹çš„",
        # åŸºç¡€æ€§åˆ«è¯
        "å¥³",
        "å¥³äºº",
        "å¥³æ€§",
        "å¥³å­",
        "å¥³ç”Ÿ",
        "å¥³å­©",
        # ç§°è°“
        "å¥³å£«",
        "å°å§",
        "ç¾å¥³",
        "å§‘å¨˜",
        "å°å§‘å¨˜",
        "å§",
        "å¦¹",
        "å§å¦¹",
        "é—ºèœœ",
        # å®¶åº­è§’è‰²
        "æ¯äº²",
        "å¦ˆå¦ˆ",
        "å¦ˆ",
        "å¥³å„¿",
        "é—ºå¥³",
        "å¦»å­",
        "è€å©†",
        "å¥³å‹",
        "å¥³æœ‹å‹",
    ],
}

# èŒä¸šè¯è¡¨ï¼ˆæ‰©å±•ç‰ˆï¼ŒæŒ‰é¢„æœŸæ€§åˆ«åˆ»æ¿ç¨‹åº¦åˆ†ç±»ï¼‰
OCCUPATION_WORDS = {
    # é¢„æœŸåå¥³æ€§çš„èŒä¸š
    "female_stereotyped": [
        "æŠ¤å£«",
        "å¹¼å¸ˆ",
        "å¹¼å„¿æ•™å¸ˆ",
        "ä¿å§†",
        "æœˆå«‚",
        "ç§˜ä¹¦",
        "å‰å°",
        "æ–‡å‘˜",
        "å®¢æœ",
        "æ”¶é“¶å‘˜",
        "å¯¼è´­",
        "ç¾å®¹å¸ˆ",
        "åŒ–å¦†å¸ˆ",
        "ç©ºå§",
        "æ¨¡ç‰¹",
        "ç‘œä¼½æ•™ç»ƒ",
    ],
    # é¢„æœŸåç”·æ€§çš„èŒä¸š
    "male_stereotyped": [
        "ç¨‹åºå‘˜",
        "å·¥ç¨‹å¸ˆ",
        "å¸æœº",
        "å¨å¸ˆ",
        "ä¿å®‰",
        "å»ºç­‘å·¥",
        "å¿«é€’å‘˜",
        "å¤–å–å‘˜",
        "ç”µå·¥",
        "æœºæ¢°å¸ˆ",
        "å†›äºº",
        "è­¦å¯Ÿ",
        "æ¶ˆé˜²å‘˜",
        "é£è¡Œå‘˜",
        "èˆ¹å‘˜",
    ],
    # é¢„æœŸç›¸å¯¹ä¸­æ€§çš„èŒä¸š
    "neutral": [
        "æ•™å¸ˆ",
        "è€å¸ˆ",
        "åŒ»ç”Ÿ",
        "ä¼šè®¡",
        "å¾‹å¸ˆ",
        "è®°è€…",
        "è®¾è®¡å¸ˆ",
        "ç¿»è¯‘",
        "ä½œå®¶",
        "æ¼”å‘˜",
        "æ­Œæ‰‹",
        "ç»ç†",
        "é”€å”®",
        "å…¬åŠ¡å‘˜",
        "èŒå‘˜",
    ],
    # é«˜åœ°ä½èŒä¸š
    "high_status": [
        "è€æ¿",
        "æ€»è£",
        "è‘£äº‹é•¿",
        "CEO",
        "é™¢é•¿",
        "æ ¡é•¿",
        "æ•™æˆ",
        "ç§‘å­¦å®¶",
        "ç ”ç©¶å‘˜",
        "ä¸“å®¶",
        "åšå£«",
    ],
}

# åˆå¹¶æ‰€æœ‰èŒä¸šè¯
ALL_OCCUPATIONS = []
for category in OCCUPATION_WORDS.values():
    ALL_OCCUPATIONS.extend(category)


def get_word_embedding(model, word):
    """è·å–è¯å‘é‡"""
    try:
        return model.wv[word]
    except KeyError:
        return None


def get_word_set_embedding(model, words):
    """è·å–ä¸€ç»„è¯çš„å¹³å‡å‘é‡ï¼ˆå½’ä¸€åŒ–ï¼‰"""
    vectors = []
    found_words = []

    for word in words:
        vec = get_word_embedding(model, word)
        if vec is not None:
            vectors.append(vec)
            found_words.append(word)

    if not vectors:
        return None, []

    # è®¡ç®—å¹³å‡å‘é‡å¹¶å½’ä¸€åŒ–
    avg_vec = np.mean(vectors, axis=0)
    normalized_vec = normalize([avg_vec])[0]

    return normalized_vec, found_words


def cosine_similarity(vec1, vec2):
    """è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦"""
    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))


def compute_gender_bias(occupation_vec, male_vec, female_vec):
    """
    è®¡ç®—èŒä¸šçš„æ€§åˆ«åå‘åˆ†æ•°

    è¿”å›ï¼š
        bias_score: æ­£å€¼=åå¥³æ€§ï¼Œè´Ÿå€¼=åç”·æ€§ï¼Œæ¥è¿‘0=ä¸­æ€§
        male_sim: ä¸ç”·æ€§è¯çš„ç›¸ä¼¼åº¦
        female_sim: ä¸å¥³æ€§è¯çš„ç›¸ä¼¼åº¦
    """
    male_sim = cosine_similarity(occupation_vec, male_vec)
    female_sim = cosine_similarity(occupation_vec, female_vec)

    # æ€§åˆ«åå‘åˆ†æ•° = å¥³æ€§ç›¸ä¼¼åº¦ - ç”·æ€§ç›¸ä¼¼åº¦
    bias_score = female_sim - male_sim

    return bias_score, male_sim, female_sim


def load_models(year, province_filter=None):
    """åŠ è½½æŒ‡å®šå¹´ä»½çš„æ‰€æœ‰æ¨¡å‹"""
    year_model_dir = os.path.join(MODEL_DIR, str(year))
    if not os.path.exists(year_model_dir):
        print(f"âŒ æœªæ‰¾åˆ° {year} å¹´çš„æ¨¡å‹ç›®å½•: {year_model_dir}")
        return {}

    pattern = os.path.join(year_model_dir, "model_*.model")
    model_files = sorted(glob.glob(pattern))

    if not model_files:
        print(f"âŒ æœªæ‰¾åˆ° {year} å¹´çš„æ¨¡å‹æ–‡ä»¶")
        return {}

    print(f"ğŸ“‚ æ‰¾åˆ° {len(model_files)} ä¸ªæ¨¡å‹æ–‡ä»¶")

    models = {}
    for model_path in model_files:
        # ä»æ–‡ä»¶åæå–çœä»½åç§°
        filename = os.path.basename(model_path)
        province = filename.replace("model_", "").replace(".model", "")

        # å¦‚æœæŒ‡å®šäº†çœä»½è¿‡æ»¤ï¼ŒåªåŠ è½½è¯¥çœä»½
        if province_filter and province != province_filter:
            continue

        try:
            model = Word2Vec.load(model_path)
            models[province] = model
            print(f"  âœ“ å·²åŠ è½½: {province} (è¯æ±‡é‡: {len(model.wv):,})")
        except Exception as e:
            print(f"  âŒ åŠ è½½å¤±è´¥: {province} - {e}")

    return models


def analyze_model(province, model):
    """åˆ†æå•ä¸ªçœä»½çš„æ¨¡å‹"""
    print(f"\n{'='*60}")
    print(f"ğŸ” åˆ†æçœä»½: {province}")
    print(f"{'='*60}")

    vocab_size = len(model.wv)
    print(f"  ğŸ“Š è¯æ±‡è¡¨å¤§å°: {vocab_size:,}")

    # è®¡ç®—æ€§åˆ«è¯å‘é‡
    male_vec, male_found = get_word_set_embedding(model, GENDER_WORDS["male"])
    female_vec, female_found = get_word_set_embedding(model, GENDER_WORDS["female"])

    if male_vec is None or female_vec is None:
        print(f"  âŒ æ€§åˆ«è¯å‘é‡è®¡ç®—å¤±è´¥")
        return None

    print(f"  âœ“ æ‰¾åˆ°ç”·æ€§è¯: {len(male_found)}/{len(GENDER_WORDS['male'])} ä¸ª")
    print(f"    {', '.join(male_found[:10])}{'...' if len(male_found) > 10 else ''}")
    print(f"  âœ“ æ‰¾åˆ°å¥³æ€§è¯: {len(female_found)}/{len(GENDER_WORDS['female'])} ä¸ª")
    print(f"    {', '.join(female_found[:10])}{'...' if len(female_found) > 10 else ''}")

    # è®¡ç®—æ¯ä¸ªèŒä¸šè¯çš„æ€§åˆ«åå‘
    occupation_results = []
    found_occupations = []

    for occupation in ALL_OCCUPATIONS:
        occ_vec = get_word_embedding(model, occupation)
        if occ_vec is not None:
            bias_score, male_sim, female_sim = compute_gender_bias(
                occ_vec, male_vec, female_vec
            )

            occupation_results.append(
                {
                    "occupation": occupation,
                    "bias_score": float(bias_score),
                    "male_similarity": float(male_sim),
                    "female_similarity": float(female_sim),
                }
            )
            found_occupations.append(occupation)

    if not occupation_results:
        print(f"  âŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•èŒä¸šè¯")
        return None

    print(f"  âœ“ æ‰¾åˆ°èŒä¸šè¯: {len(found_occupations)}/{len(ALL_OCCUPATIONS)} ä¸ª")

    # æ’åºå¹¶å±•ç¤ºç»“æœ
    occupation_results_sorted = sorted(
        occupation_results, key=lambda x: x["bias_score"], reverse=True
    )

    print(f"\n  ğŸ“Š èŒä¸šæ€§åˆ«åå‘åˆ†æ:")
    print(f"\n  ğŸ”µ æœ€åå¥³æ€§çš„èŒä¸š (Top 5):")
    for i, occ in enumerate(occupation_results_sorted[:5], 1):
        print(
            f"    {i}. {occ['occupation']:8s} | åå‘åˆ†æ•°: {occ['bias_score']:+.3f} "
            f"| å¥³æ€§ç›¸ä¼¼åº¦: {occ['female_similarity']:.3f} "
            f"| ç”·æ€§ç›¸ä¼¼åº¦: {occ['male_similarity']:.3f}"
        )

    print(f"\n  ğŸ”´ æœ€åç”·æ€§çš„èŒä¸š (Top 5):")
    for i, occ in enumerate(occupation_results_sorted[-5:][::-1], 1):
        print(
            f"    {i}. {occ['occupation']:8s} | åå‘åˆ†æ•°: {occ['bias_score']:+.3f} "
            f"| å¥³æ€§ç›¸ä¼¼åº¦: {occ['female_similarity']:.3f} "
            f"| ç”·æ€§ç›¸ä¼¼åº¦: {occ['male_similarity']:.3f}"
        )

    # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
    bias_scores = [r["bias_score"] for r in occupation_results]
    stats = {
        "province": province,
        "vocab_size": vocab_size,
        "occupations_found": len(found_occupations),
        "male_words_found": len(male_found),
        "female_words_found": len(female_found),
        "mean_bias": float(np.mean(bias_scores)),
        "std_bias": float(np.std(bias_scores)),
        "min_bias": float(np.min(bias_scores)),
        "max_bias": float(np.max(bias_scores)),
        "range_bias": float(np.max(bias_scores) - np.min(bias_scores)),
    }

    print(f"\n  ğŸ“ˆ ç»Ÿè®¡æŒ‡æ ‡:")
    print(f"    å¹³å‡åå‘: {stats['mean_bias']:+.3f}")
    print(f"    æ ‡å‡†å·®ï¼ˆéš”ç¦»ç¨‹åº¦ï¼‰: {stats['std_bias']:.3f}")
    print(f"    åå‘èŒƒå›´: [{stats['min_bias']:+.3f}, {stats['max_bias']:+.3f}]")

    # è¿”å›åˆ†æç»“æœ
    result = {
        "province": province,
        "stats": stats,
        "male_vec": male_vec.tolist(),
        "female_vec": female_vec.tolist(),
        "male_words_found": male_found,
        "female_words_found": female_found,
        "occupations_found": found_occupations,
        "occupation_results": occupation_results,
    }

    return result


def analyze_all_models(models):
    """åˆ†ææ‰€æœ‰çœä»½çš„æ¨¡å‹"""
    results = []
    province_stats = []

    for province, model in models.items():
        result = analyze_model(province, model)
        if result:
            results.append(result)
            province_stats.append(result["stats"])

    return results, province_stats


def save_results(results, province_stats, year):
    """ä¿å­˜åˆ†æç»“æœ"""
    if not results:
        print("âŒ æ²¡æœ‰ç”Ÿæˆä»»ä½•ç»“æœ")
        return

    year_output_dir = os.path.join(OUTPUT_DIR, str(year))
    os.makedirs(year_output_dir, exist_ok=True)

    print(f"\n{'='*60}")
    print(f"ğŸ’¾ ä¿å­˜ç»“æœ...")
    print(f"{'='*60}")

    # 1. ä¿å­˜çœä»½ç»Ÿè®¡ä¿¡æ¯
    stats_df = pd.DataFrame(province_stats)
    stats_file = os.path.join(year_output_dir, f"province_stats.csv")
    stats_df.to_csv(stats_file, index=False, encoding="utf-8-sig")
    print(f"âœ“ çœä»½ç»Ÿè®¡ä¿¡æ¯: {stats_file}")

    # 2. ä¿å­˜èŒä¸šæ€§åˆ«åå‘è¯¦ç»†æ•°æ®ï¼ˆé•¿æ ¼å¼ï¼‰
    occupation_data = []
    for result in results:
        province = result["province"]
        for occ in result["occupation_results"]:
            occupation_data.append(
                {
                    "province": province,
                    "occupation": occ["occupation"],
                    "bias_score": occ["bias_score"],
                    "male_similarity": occ["male_similarity"],
                    "female_similarity": occ["female_similarity"],
                }
            )

    occupation_df = pd.DataFrame(occupation_data)
    occupation_file = os.path.join(year_output_dir, f"occupation_bias.csv")
    occupation_df.to_csv(occupation_file, index=False, encoding="utf-8-sig")
    print(f"âœ“ èŒä¸šæ€§åˆ«åå‘æ•°æ®: {occupation_file}")

    # 3. ä¿å­˜å®½æ ¼å¼æ•°æ®ï¼ˆçœä»½Ã—èŒä¸šçŸ©é˜µï¼‰
    pivot_df = occupation_df.pivot_table(
        values="bias_score", index="occupation", columns="province", aggfunc="mean"
    )
    pivot_file = os.path.join(year_output_dir, f"occupation_bias_pivot.csv")
    pivot_df.to_csv(pivot_file, encoding="utf-8-sig")
    print(f"âœ“ èŒä¸šÃ—çœä»½çŸ©é˜µ: {pivot_file}")

    # 4. ä¿å­˜è¯¦ç»†å‘é‡æ•°æ®ï¼ˆJSONæ ¼å¼ï¼‰
    detailed_data = []
    for result in results:
        detailed_data.append(
            {
                "province": result["province"],
                "stats": result["stats"],
                "male_vec": result["male_vec"],
                "female_vec": result["female_vec"],
                "male_words_found": result["male_words_found"],
                "female_words_found": result["female_words_found"],
                "occupations_found": result["occupations_found"],
            }
        )

    detailed_file = os.path.join(year_output_dir, f"detailed_vectors.json")
    with open(detailed_file, "w", encoding="utf-8") as f:
        json.dump(detailed_data, f, ensure_ascii=False, indent=2)
    print(f"âœ“ è¯¦ç»†å‘é‡æ•°æ®: {detailed_file}")

    # 5. ç”Ÿæˆç®€è¦åˆ†ææŠ¥å‘Š
    report_file = os.path.join(year_output_dir, f"analysis_report.txt")
    with open(report_file, "w", encoding="utf-8") as f:
        f.write(f"{'='*60}\n")
        f.write(f"æ€§åˆ«-èŒä¸šEmbeddingåˆ†ææŠ¥å‘Š ({year}å¹´)\n")
        f.write(f"{'='*60}\n\n")

        f.write(f"åˆ†æçœä»½æ•°: {len(results)}\n")
        f.write(f"åˆ†æèŒä¸šæ•°: {len(ALL_OCCUPATIONS)}\n\n")

        f.write(f"{'='*60}\n")
        f.write(f"å„çœä»½æ€§åˆ«éš”ç¦»æŒ‡æ•°æ’åï¼ˆæ ‡å‡†å·®ï¼‰:\n")
        f.write(f"{'='*60}\n")
        stats_sorted = sorted(province_stats, key=lambda x: x["std_bias"], reverse=True)
        for i, stat in enumerate(stats_sorted, 1):
            f.write(
                f"{i:2d}. {stat['province']:10s} | "
                f"éš”ç¦»æŒ‡æ•°: {stat['std_bias']:.3f} | "
                f"å¹³å‡åå‘: {stat['mean_bias']:+.3f}\n"
            )

        f.write(f"\n{'='*60}\n")
        f.write(f"èŒä¸šæ€§åˆ«åå‘ä¸€è‡´æ€§åˆ†æ:\n")
        f.write(f"{'='*60}\n")

        # è®¡ç®—æ¯ä¸ªèŒä¸šåœ¨å„çœä»½çš„å¹³å‡åå‘
        occupation_avg = (
            occupation_df.groupby("occupation")["bias_score"]
            .agg(["mean", "std"])
            .sort_values("mean", ascending=False)
        )

        f.write(f"\næœ€åå¥³æ€§çš„èŒä¸šï¼ˆè·¨çœä»½å¹³å‡ï¼‰:\n")
        for i, (occ, row) in enumerate(occupation_avg.head(10).iterrows(), 1):
            f.write(
                f"  {i:2d}. {occ:15s} | å¹³å‡: {row['mean']:+.3f} | æ ‡å‡†å·®: {row['std']:.3f}\n"
            )

        f.write(f"\næœ€åç”·æ€§çš„èŒä¸šï¼ˆè·¨çœä»½å¹³å‡ï¼‰:\n")
        for i, (occ, row) in enumerate(
            occupation_avg.tail(10).iloc[::-1].iterrows(), 1
        ):
            f.write(
                f"  {i:2d}. {occ:15s} | å¹³å‡: {row['mean']:+.3f} | æ ‡å‡†å·®: {row['std']:.3f}\n"
            )

        f.write(f"\nèŒä¸šåå‘å·®å¼‚æœ€å¤§çš„ï¼ˆè·¨çœä»½æ ‡å‡†å·®æœ€å¤§ï¼‰:\n")
        occupation_var = occupation_avg.sort_values("std", ascending=False)
        for i, (occ, row) in enumerate(occupation_var.head(10).iterrows(), 1):
            f.write(
                f"  {i:2d}. {occ:15s} | å¹³å‡: {row['mean']:+.3f} | æ ‡å‡†å·®: {row['std']:.3f}\n"
            )

    print(f"âœ“ åˆ†ææŠ¥å‘Š: {report_file}")

    print(f"\nâœ… æ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ° {year_output_dir}/ ç›®å½•")


def main(year: int, province: str = None):
    """
    è¿è¡Œembeddingåˆ†æ

    Args:
        year: å¹´ä»½
        province: æŒ‡å®šçœä»½ï¼ˆå¯é€‰ï¼‰ï¼Œå¦‚æœä¸æŒ‡å®šåˆ™åˆ†ææ‰€æœ‰çœä»½
    """
    print(f"\n{'='*60}")
    print(f"ğŸš€ å¼€å§‹åˆ†æ {year} å¹´æ•°æ®çš„æ€§åˆ«-èŒä¸šEmbedding")
    print(f"{'='*60}\n")

    # åŠ è½½æ¨¡å‹
    models = load_models(year, province)
    if not models:
        print("âŒ æ— æ³•åŠ è½½æ¨¡å‹")
        return

    # åˆ†ææ¨¡å‹
    results, province_stats = analyze_all_models(models)

    # ä¿å­˜ç»“æœ
    save_results(results, province_stats, year)

    print(f"\n{'='*60}")
    print(f"ğŸ‰ {year} å¹´embeddingåˆ†æå®Œæˆï¼")
    print(f"{'='*60}\n")


if __name__ == "__main__":
    fire.Fire(main)
