"""
æ€§åˆ«å’ŒèŒä¸šè¯çš„embeddingåˆ†æå™¨

åŠŸèƒ½ï¼š
1. åŠ è½½å·²è®­ç»ƒçš„Word2Vecæ¨¡å‹
2. è®¡ç®—èŒä¸šè¯ä¸æ€§åˆ«è¯çš„å…³è”åº¦ï¼ˆåˆ†åˆ«è®¡ç®—ä¸ç”·æ€§è¯ã€å¥³æ€§è¯çš„ç›¸ä¼¼åº¦ï¼‰
3. æ¯”è¾ƒä¸åŒçœä»½æ¨¡å‹çš„å·®å¼‚
4. åˆ†æå®¶åŠ¡åˆ†å·¥è¯æ±‡ï¼ˆå®¶åº­åœºåŸŸ vs å·¥ä½œåœºåŸŸï¼‰çš„æ€§åˆ«å·®å¼‚
5. ç”Ÿæˆåˆ†ææŠ¥å‘Šå’Œå¯è§†åŒ–æ•°æ®

è¾“å…¥ï¼šgender_embedding/embedding_models/{year}/ ä¸‹çš„æ¨¡å‹æ–‡ä»¶
è¾“å‡ºï¼šembedding_analysis/{year}/ ä¸‹çš„åˆ†æç»“æœ
"""

import os
import pandas as pd
import numpy as np
from gensim.models import KeyedVectors
import fire
from sklearn.preprocessing import normalize
import warnings
import json
import glob

warnings.filterwarnings("ignore")

MODEL_DIR = "gender_embedding/embedding_models"
OUTPUT_DIR = "embedding_analysis"
WORDLISTS_DIR = "wordlists"

# ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
os.makedirs(OUTPUT_DIR, exist_ok=True)
os.makedirs(WORDLISTS_DIR, exist_ok=True)


def load_json_wordlist(filename):
    """
    ä»JSONæ–‡ä»¶åŠ è½½è¯è¡¨

    Args:
        filename: JSONè¯è¡¨æ–‡ä»¶åï¼ˆåœ¨wordlistsç›®å½•ä¸‹ï¼‰

    Returns:
        dict: è¯è¡¨å­—å…¸
    """
    filepath = os.path.join(WORDLISTS_DIR, filename)
    if not os.path.exists(filepath):
        print(f"âš ï¸  è¯è¡¨æ–‡ä»¶ä¸å­˜åœ¨: {filepath}")
        return {}

    try:
        with open(filepath, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception as e:
        print(f"âŒ åŠ è½½è¯è¡¨æ–‡ä»¶å¤±è´¥ {filepath}: {e}")
        return {}


def load_gender_words():
    """åŠ è½½æ€§åˆ«è¯è¡¨"""
    data = load_json_wordlist("gender_words.json")
    return {"male": data.get("male", []), "female": data.get("female", [])}


def load_occupation_words():
    """åŠ è½½èŒä¸šè¯è¡¨ï¼Œè¿”å›æ‰€æœ‰èŒä¸šè¯çš„åˆ—è¡¨"""
    data = load_json_wordlist("occupation_words.json")
    all_occupations = []
    for category in data.values():
        all_occupations.extend(category)
    return all_occupations


def load_domestic_work_words():
    """åŠ è½½å®¶åŠ¡åˆ†å·¥è¯è¡¨"""
    data = load_json_wordlist("domestic_work_words.json")
    return {"family": data.get("family", []), "work": data.get("work", [])}


# åŠ è½½è¯è¡¨
GENDER_WORDS = load_gender_words()
ALL_OCCUPATIONS = load_occupation_words()
DOMESTIC_WORK_WORDS = load_domestic_work_words()


def get_word_embedding(model, word):
    """è·å–è¯å‘é‡"""
    try:
        return model[word]
    except KeyError:
        return None


def get_word_set_embedding(model, words):
    """è·å–ä¸€ç»„è¯çš„å¹³å‡å‘é‡ï¼ˆå½’ä¸€åŒ–ï¼‰"""
    vectors = []
    found_words = []

    for word in words:
        vec = get_word_embedding(model, word)
        if vec is not None:
            vectors.append(vec)
            found_words.append(word)

    if not vectors:
        return None, []

    # è®¡ç®—å¹³å‡å‘é‡å¹¶å½’ä¸€åŒ–
    avg_vec = np.mean(vectors, axis=0)
    normalized_vec = normalize([avg_vec])[0]

    return normalized_vec, found_words


def cosine_similarity(vec1, vec2):
    """è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦"""
    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))


def compute_gender_bias(occupation_vec, male_vec, female_vec):
    """
    è®¡ç®—èŒä¸šçš„æ€§åˆ«åå‘åˆ†æ•°ï¼ˆåŸºäºä½™å¼¦ç›¸ä¼¼åº¦å·®å€¼ï¼‰

    è¿”å›ï¼š
        bias_score: æ­£å€¼=åå¥³æ€§ï¼Œè´Ÿå€¼=åç”·æ€§ï¼Œæ¥è¿‘0=ä¸­æ€§
        male_sim: ä¸ç”·æ€§è¯çš„ç›¸ä¼¼åº¦
        female_sim: ä¸å¥³æ€§è¯çš„ç›¸ä¼¼åº¦
    """
    male_sim = cosine_similarity(occupation_vec, male_vec)
    female_sim = cosine_similarity(occupation_vec, female_vec)

    # æ€§åˆ«åå‘åˆ†æ•° = å¥³æ€§ç›¸ä¼¼åº¦ - ç”·æ€§ç›¸ä¼¼åº¦
    bias_score = female_sim - male_sim

    return bias_score, male_sim, female_sim


def compute_gender_bias_projection(occupation_vec, male_vec, female_vec):
    """
    è®¡ç®—èŒä¸šçš„æ€§åˆ«åå‘åˆ†æ•°ï¼ˆåŸºäºæ€§åˆ«è½´æŠ•å½±ï¼‰

    æ„å»ºæ€§åˆ«è½´ï¼šä»ç”·æ€§å‘é‡æŒ‡å‘å¥³æ€§å‘é‡çš„æ–¹å‘å‘é‡ï¼ˆæ­£å‘ä¸ºå¥³æ€§ï¼Œè´Ÿå‘ä¸ºç”·æ€§ï¼‰
    è®¡ç®—èŒä¸šè¯å‘é‡åœ¨æ€§åˆ«è½´ä¸Šçš„æŠ•å½±å€¼

    è¿”å›ï¼š
        projection_score: æŠ•å½±å€¼ï¼Œæ­£å€¼=åå¥³æ€§ï¼Œè´Ÿå€¼=åç”·æ€§ï¼Œæ¥è¿‘0=ä¸­æ€§
        gender_axis: æ€§åˆ«è½´æ–¹å‘å‘é‡ï¼ˆå½’ä¸€åŒ–ï¼‰
    """
    # æ„å»ºæ€§åˆ«è½´ï¼šå¥³æ€§å‘é‡ - ç”·æ€§å‘é‡ï¼ˆæ­£å‘ä¸ºå¥³æ€§æ–¹å‘ï¼‰
    gender_axis = female_vec - male_vec

    # å½’ä¸€åŒ–æ€§åˆ«è½´
    axis_norm = np.linalg.norm(gender_axis)
    if axis_norm > 0:
        gender_axis_normalized = gender_axis / axis_norm
    else:
        # å¦‚æœæ€§åˆ«è½´ä¸ºé›¶å‘é‡ï¼Œè¿”å›0
        return 0.0, gender_axis

    # è®¡ç®—èŒä¸šè¯å‘é‡åœ¨æ€§åˆ«è½´ä¸Šçš„æŠ•å½±
    # projection = dot(occupation_vec, gender_axis_normalized)
    projection_score = np.dot(occupation_vec, gender_axis_normalized)

    return projection_score, gender_axis_normalized


def compute_domain_bias(word_vec, family_vec, work_vec):
    """
    è®¡ç®—è¯æ±‡åœ¨å®¶åº­åœºåŸŸ vs å·¥ä½œåœºåŸŸçš„åå‘åˆ†æ•°

    è¿”å›ï¼š
        bias_score: æ­£å€¼=åå®¶åº­åœºåŸŸï¼Œè´Ÿå€¼=åå·¥ä½œåœºåŸŸï¼Œæ¥è¿‘0=ä¸­æ€§
        family_sim: ä¸å®¶åº­åœºåŸŸè¯çš„ç›¸ä¼¼åº¦
        work_sim: ä¸å·¥ä½œåœºåŸŸè¯çš„ç›¸ä¼¼åº¦
    """
    family_sim = cosine_similarity(word_vec, family_vec)
    work_sim = cosine_similarity(word_vec, work_vec)

    # åœºåŸŸåå‘åˆ†æ•° = å®¶åº­ç›¸ä¼¼åº¦ - å·¥ä½œç›¸ä¼¼åº¦
    bias_score = family_sim - work_sim

    return bias_score, family_sim, work_sim


def load_models(year, province_filter=None):
    """åŠ è½½æŒ‡å®šå¹´ä»½çš„æ‰€æœ‰æ¨¡å‹"""
    year_model_dir = os.path.join(MODEL_DIR, str(year))
    if not os.path.exists(year_model_dir):
        print(f"âŒ æœªæ‰¾åˆ° {year} å¹´çš„æ¨¡å‹ç›®å½•: {year_model_dir}")
        return {}

    pattern = os.path.join(year_model_dir, "model_*.model")
    model_files = sorted(glob.glob(pattern))

    if not model_files:
        print(f"âŒ æœªæ‰¾åˆ° {year} å¹´çš„æ¨¡å‹æ–‡ä»¶")
        return {}

    print(f"ğŸ“‚ æ‰¾åˆ° {len(model_files)} ä¸ªæ¨¡å‹æ–‡ä»¶")

    models = {}
    for model_path in model_files:
        # ä»æ–‡ä»¶åæå–çœä»½åç§°
        filename = os.path.basename(model_path)
        province = filename.replace("model_", "").replace(".model", "")

        # å¦‚æœæŒ‡å®šäº†çœä»½è¿‡æ»¤ï¼ŒåªåŠ è½½è¯¥çœä»½
        if province_filter and province != province_filter:
            continue

        try:
            model = KeyedVectors.load(model_path)
            models[province] = model
            print(f"  âœ“ å·²åŠ è½½: {province} (è¯æ±‡é‡: {len(model):,})")
        except Exception as e:
            print(f"  âŒ åŠ è½½å¤±è´¥: {province} - {e}")

    return models


def analyze_model(province, model):
    """åˆ†æå•ä¸ªçœä»½çš„æ¨¡å‹"""
    print(f"\n{'='*60}")
    print(f"ğŸ” åˆ†æçœä»½: {province}")
    print(f"{'='*60}")

    vocab_size = len(model)
    print(f"  ğŸ“Š è¯æ±‡è¡¨å¤§å°: {vocab_size:,}")

    # è®¡ç®—æ€§åˆ«è¯å‘é‡
    male_vec, male_found = get_word_set_embedding(model, GENDER_WORDS["male"])
    female_vec, female_found = get_word_set_embedding(model, GENDER_WORDS["female"])

    if male_vec is None or female_vec is None:
        print(f"  âŒ æ€§åˆ«è¯å‘é‡è®¡ç®—å¤±è´¥")
        return None

    print(f"  âœ“ æ‰¾åˆ°ç”·æ€§è¯: {len(male_found)}/{len(GENDER_WORDS['male'])} ä¸ª")
    print(f"    {', '.join(male_found[:10])}{'...' if len(male_found) > 10 else ''}")
    print(f"  âœ“ æ‰¾åˆ°å¥³æ€§è¯: {len(female_found)}/{len(GENDER_WORDS['female'])} ä¸ª")
    print(
        f"    {', '.join(female_found[:10])}{'...' if len(female_found) > 10 else ''}"
    )

    # è®¡ç®—æ¯ä¸ªèŒä¸šè¯çš„æ€§åˆ«åå‘ï¼ˆä½¿ç”¨ä¸¤ç§æ–¹æ³•ï¼‰
    occupation_results = []
    found_occupations = []

    for occupation in ALL_OCCUPATIONS:
        occ_vec = get_word_embedding(model, occupation)
        if occ_vec is not None:
            # æ–¹æ³•1ï¼šä½™å¼¦ç›¸ä¼¼åº¦å·®å€¼
            bias_score, male_sim, female_sim = compute_gender_bias(
                occ_vec, male_vec, female_vec
            )

            # æ–¹æ³•2ï¼šæ€§åˆ«è½´æŠ•å½±
            projection_score, _ = compute_gender_bias_projection(
                occ_vec, male_vec, female_vec
            )

            occupation_results.append(
                {
                    "occupation": occupation,
                    "bias_score": float(bias_score),  # ä½™å¼¦ç›¸ä¼¼åº¦å·®å€¼æ–¹æ³•
                    "projection_score": float(projection_score),  # æ€§åˆ«è½´æŠ•å½±æ–¹æ³•
                    "male_similarity": float(male_sim),
                    "female_similarity": float(female_sim),
                }
            )
            found_occupations.append(occupation)

    if not occupation_results:
        print(f"  âŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•èŒä¸šè¯")
        return None

    print(f"  âœ“ æ‰¾åˆ°èŒä¸šè¯: {len(found_occupations)}/{len(ALL_OCCUPATIONS)} ä¸ª")

    # æ’åºå¹¶å±•ç¤ºç»“æœï¼ˆæŒ‰ä½™å¼¦ç›¸ä¼¼åº¦å·®å€¼ï¼‰
    occupation_results_sorted = sorted(
        occupation_results, key=lambda x: x["bias_score"], reverse=True
    )

    print(f"\n  ğŸ“Š èŒä¸šæ€§åˆ«åå‘åˆ†æï¼ˆä½™å¼¦ç›¸ä¼¼åº¦å·®å€¼æ–¹æ³•ï¼‰:")
    print(f"\n  ğŸ”µ æœ€åå¥³æ€§çš„èŒä¸š (Top 5):")
    for i, occ in enumerate(occupation_results_sorted[:5], 1):
        print(
            f"    {i}. {occ['occupation']:8s} | åå‘åˆ†æ•°: {occ['bias_score']:+.3f} "
            f"| æŠ•å½±åˆ†æ•°: {occ['projection_score']:+.3f} "
            f"| å¥³æ€§ç›¸ä¼¼åº¦: {occ['female_similarity']:.3f} "
            f"| ç”·æ€§ç›¸ä¼¼åº¦: {occ['male_similarity']:.3f}"
        )

    print(f"\n  ğŸ”´ æœ€åç”·æ€§çš„èŒä¸š (Top 5):")
    for i, occ in enumerate(occupation_results_sorted[-5:][::-1], 1):
        print(
            f"    {i}. {occ['occupation']:8s} | åå‘åˆ†æ•°: {occ['bias_score']:+.3f} "
            f"| æŠ•å½±åˆ†æ•°: {occ['projection_score']:+.3f} "
            f"| å¥³æ€§ç›¸ä¼¼åº¦: {occ['female_similarity']:.3f} "
            f"| ç”·æ€§ç›¸ä¼¼åº¦: {occ['male_similarity']:.3f}"
        )

    # æŒ‰æŠ•å½±åˆ†æ•°æ’åºå¹¶å±•ç¤º
    occupation_results_sorted_proj = sorted(
        occupation_results, key=lambda x: x["projection_score"], reverse=True
    )

    print(f"\n  ğŸ“Š èŒä¸šæ€§åˆ«åå‘åˆ†æï¼ˆæ€§åˆ«è½´æŠ•å½±æ–¹æ³•ï¼‰:")
    print(f"\n  ğŸ”µ æœ€åå¥³æ€§çš„èŒä¸š (Top 5):")
    for i, occ in enumerate(occupation_results_sorted_proj[:5], 1):
        print(
            f"    {i}. {occ['occupation']:8s} | æŠ•å½±åˆ†æ•°: {occ['projection_score']:+.3f} "
            f"| åå‘åˆ†æ•°: {occ['bias_score']:+.3f}"
        )

    print(f"\n  ğŸ”´ æœ€åç”·æ€§çš„èŒä¸š (Top 5):")
    for i, occ in enumerate(occupation_results_sorted_proj[-5:][::-1], 1):
        print(
            f"    {i}. {occ['occupation']:8s} | æŠ•å½±åˆ†æ•°: {occ['projection_score']:+.3f} "
            f"| åå‘åˆ†æ•°: {occ['bias_score']:+.3f}"
        )

    # è®¡ç®—å®¶åŠ¡åˆ†å·¥è¯æ±‡åˆ†æ
    family_vec, family_found = get_word_set_embedding(
        model, DOMESTIC_WORK_WORDS["family"]
    )
    work_vec, work_found = get_word_set_embedding(model, DOMESTIC_WORK_WORDS["work"])

    domestic_work_results = []
    if family_vec is not None and work_vec is not None:
        print(f"\n  ğŸ“Š å®¶åŠ¡åˆ†å·¥åœºåŸŸåˆ†æ:")
        print(
            f"  âœ“ æ‰¾åˆ°å®¶åº­åœºåŸŸè¯: {len(family_found)}/{len(DOMESTIC_WORK_WORDS['family'])} ä¸ª"
        )
        print(
            f"  âœ“ æ‰¾åˆ°å·¥ä½œåœºåŸŸè¯: {len(work_found)}/{len(DOMESTIC_WORK_WORDS['work'])} ä¸ª"
        )

        # è®¡ç®—ç”·æ€§è¯å’Œå¥³æ€§è¯åœ¨å®¶åº­åœºåŸŸ vs å·¥ä½œåœºåŸŸçš„åå‘
        male_domain_bias, male_family_sim, male_work_sim = compute_domain_bias(
            male_vec, family_vec, work_vec
        )
        female_domain_bias, female_family_sim, female_work_sim = compute_domain_bias(
            female_vec, family_vec, work_vec
        )

        domestic_work_results.append(
            {
                "word_type": "male",
                "domain_bias": float(male_domain_bias),
                "family_similarity": float(male_family_sim),
                "work_similarity": float(male_work_sim),
            }
        )
        domestic_work_results.append(
            {
                "word_type": "female",
                "domain_bias": float(female_domain_bias),
                "family_similarity": float(female_family_sim),
                "work_similarity": float(female_work_sim),
            }
        )

        print(f"\n  ğŸ  æ€§åˆ«åœ¨å®¶åº­åœºåŸŸ vs å·¥ä½œåœºåŸŸçš„åå‘:")
        print(
            f"    ç”·æ€§: åœºåŸŸåå‘åˆ†æ•° {male_domain_bias:+.3f} "
            f"(å®¶åº­: {male_family_sim:.3f}, å·¥ä½œ: {male_work_sim:.3f})"
        )
        print(
            f"    å¥³æ€§: åœºåŸŸåå‘åˆ†æ•° {female_domain_bias:+.3f} "
            f"(å®¶åº­: {female_family_sim:.3f}, å·¥ä½œ: {female_work_sim:.3f})"
        )
        print(
            f"    æ€§åˆ«å·®å¼‚: {female_domain_bias - male_domain_bias:+.3f} "
            f"(æ­£å€¼è¡¨ç¤ºå¥³æ€§æ›´åå‘å®¶åº­åœºåŸŸ)"
        )

    # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
    bias_scores = [r["bias_score"] for r in occupation_results]
    projection_scores = [r["projection_score"] for r in occupation_results]
    stats = {
        "province": province,
        "vocab_size": vocab_size,
        "occupations_found": len(found_occupations),
        "male_words_found": len(male_found),
        "female_words_found": len(female_found),
        # ä½™å¼¦ç›¸ä¼¼åº¦å·®å€¼æ–¹æ³•çš„ç»Ÿè®¡
        "mean_bias": float(np.mean(bias_scores)),
        "std_bias": float(np.std(bias_scores)),
        "min_bias": float(np.min(bias_scores)),
        "max_bias": float(np.max(bias_scores)),
        "range_bias": float(np.max(bias_scores) - np.min(bias_scores)),
        # æ€§åˆ«è½´æŠ•å½±æ–¹æ³•çš„ç»Ÿè®¡
        "mean_projection": float(np.mean(projection_scores)),
        "std_projection": float(np.std(projection_scores)),
        "min_projection": float(np.min(projection_scores)),
        "max_projection": float(np.max(projection_scores)),
        "range_projection": float(
            np.max(projection_scores) - np.min(projection_scores)
        ),
    }

    if domestic_work_results:
        male_domain = next(
            (r for r in domestic_work_results if r["word_type"] == "male"), None
        )
        female_domain = next(
            (r for r in domestic_work_results if r["word_type"] == "female"), None
        )
        if male_domain and female_domain:
            stats["male_domain_bias"] = male_domain["domain_bias"]
            stats["female_domain_bias"] = female_domain["domain_bias"]
            stats["gender_domain_gap"] = (
                female_domain["domain_bias"] - male_domain["domain_bias"]
            )

    print(f"\n  ğŸ“ˆ ç»Ÿè®¡æŒ‡æ ‡:")
    print(f"    ä½™å¼¦ç›¸ä¼¼åº¦å·®å€¼æ–¹æ³•:")
    print(f"      å¹³å‡åå‘: {stats['mean_bias']:+.3f}")
    print(f"      æ ‡å‡†å·®ï¼ˆéš”ç¦»ç¨‹åº¦ï¼‰: {stats['std_bias']:.3f}")
    print(f"      åå‘èŒƒå›´: [{stats['min_bias']:+.3f}, {stats['max_bias']:+.3f}]")
    print(f"    æ€§åˆ«è½´æŠ•å½±æ–¹æ³•:")
    print(f"      å¹³å‡æŠ•å½±: {stats['mean_projection']:+.3f}")
    print(f"      æ ‡å‡†å·®: {stats['std_projection']:.3f}")
    print(
        f"      æŠ•å½±èŒƒå›´: [{stats['min_projection']:+.3f}, {stats['max_projection']:+.3f}]"
    )

    # è¿”å›åˆ†æç»“æœ
    result = {
        "province": province,
        "stats": stats,
        "male_vec": male_vec.tolist(),
        "female_vec": female_vec.tolist(),
        "male_words_found": male_found,
        "female_words_found": female_found,
        "occupations_found": found_occupations,
        "occupation_results": occupation_results,
        "domestic_work_results": domestic_work_results,
        "family_words_found": family_found if family_vec is not None else [],
        "work_words_found": work_found if work_vec is not None else [],
    }

    return result


def analyze_all_models(models):
    """åˆ†ææ‰€æœ‰çœä»½çš„æ¨¡å‹"""
    results = []
    province_stats = []

    for province, model in models.items():
        result = analyze_model(province, model)
        if result:
            results.append(result)
            province_stats.append(result["stats"])

    return results, province_stats


def save_results(results, province_stats, year):
    """ä¿å­˜åˆ†æç»“æœ"""
    if not results:
        print("âŒ æ²¡æœ‰ç”Ÿæˆä»»ä½•ç»“æœ")
        return

    year_output_dir = os.path.join(OUTPUT_DIR, str(year))
    os.makedirs(year_output_dir, exist_ok=True)

    print(f"\n{'='*60}")
    print(f"ğŸ’¾ ä¿å­˜ç»“æœ...")
    print(f"{'='*60}")

    # 1. ä¿å­˜çœä»½ç»Ÿè®¡ä¿¡æ¯
    stats_df = pd.DataFrame(province_stats)
    stats_file = os.path.join(year_output_dir, f"province_stats.csv")
    stats_df.to_csv(stats_file, index=False, encoding="utf-8-sig")
    print(f"âœ“ çœä»½ç»Ÿè®¡ä¿¡æ¯: {stats_file}")

    # 2. ä¿å­˜èŒä¸šæ€§åˆ«åå‘è¯¦ç»†æ•°æ®ï¼ˆé•¿æ ¼å¼ï¼‰
    occupation_data = []
    for result in results:
        province = result["province"]
        for occ in result["occupation_results"]:
            occupation_data.append(
                {
                    "province": province,
                    "occupation": occ["occupation"],
                    "bias_score": occ["bias_score"],  # ä½™å¼¦ç›¸ä¼¼åº¦å·®å€¼æ–¹æ³•
                    "projection_score": occ["projection_score"],  # æ€§åˆ«è½´æŠ•å½±æ–¹æ³•
                    "male_similarity": occ["male_similarity"],
                    "female_similarity": occ["female_similarity"],
                }
            )

    occupation_df = pd.DataFrame(occupation_data)
    occupation_file = os.path.join(year_output_dir, f"occupation_bias.csv")
    occupation_df.to_csv(occupation_file, index=False, encoding="utf-8-sig")
    print(f"âœ“ èŒä¸šæ€§åˆ«åå‘æ•°æ®: {occupation_file}")

    # 2.5. ä¿å­˜å®¶åŠ¡åˆ†å·¥åœºåŸŸåå‘æ•°æ®
    domestic_work_data = []
    for result in results:
        province = result["province"]
        if result.get("domestic_work_results"):
            for dw in result["domestic_work_results"]:
                domestic_work_data.append(
                    {
                        "province": province,
                        "word_type": dw["word_type"],
                        "domain_bias": dw["domain_bias"],
                        "family_similarity": dw["family_similarity"],
                        "work_similarity": dw["work_similarity"],
                    }
                )

    if domestic_work_data:
        domestic_work_df = pd.DataFrame(domestic_work_data)
        domestic_work_file = os.path.join(year_output_dir, f"domestic_work_bias.csv")
        domestic_work_df.to_csv(domestic_work_file, index=False, encoding="utf-8-sig")
        print(f"âœ“ å®¶åŠ¡åˆ†å·¥åœºåŸŸåå‘æ•°æ®: {domestic_work_file}")

    # 3. ä¿å­˜å®½æ ¼å¼æ•°æ®ï¼ˆçœä»½Ã—èŒä¸šçŸ©é˜µï¼‰
    # 3.1 ä½™å¼¦ç›¸ä¼¼åº¦å·®å€¼æ–¹æ³•çš„çŸ©é˜µ
    pivot_df = occupation_df.pivot_table(
        values="bias_score", index="occupation", columns="province", aggfunc="mean"
    )
    pivot_file = os.path.join(year_output_dir, f"occupation_bias_pivot.csv")
    pivot_df.to_csv(pivot_file, encoding="utf-8-sig")
    print(f"âœ“ èŒä¸šÃ—çœä»½çŸ©é˜µï¼ˆä½™å¼¦ç›¸ä¼¼åº¦å·®å€¼ï¼‰: {pivot_file}")

    # 3.2 æ€§åˆ«è½´æŠ•å½±æ–¹æ³•çš„çŸ©é˜µ
    pivot_proj_df = occupation_df.pivot_table(
        values="projection_score",
        index="occupation",
        columns="province",
        aggfunc="mean",
    )
    pivot_proj_file = os.path.join(year_output_dir, f"occupation_projection_pivot.csv")
    pivot_proj_df.to_csv(pivot_proj_file, encoding="utf-8-sig")
    print(f"âœ“ èŒä¸šÃ—çœä»½çŸ©é˜µï¼ˆæ€§åˆ«è½´æŠ•å½±ï¼‰: {pivot_proj_file}")

    # 4. ä¿å­˜è¯¦ç»†å‘é‡æ•°æ®ï¼ˆJSONæ ¼å¼ï¼‰
    detailed_data = []
    for result in results:
        detailed_data.append(
            {
                "province": result["province"],
                "stats": result["stats"],
                "male_vec": result["male_vec"],
                "female_vec": result["female_vec"],
                "male_words_found": result["male_words_found"],
                "female_words_found": result["female_words_found"],
                "occupations_found": result["occupations_found"],
            }
        )

    detailed_file = os.path.join(year_output_dir, f"detailed_vectors.json")
    with open(detailed_file, "w", encoding="utf-8") as f:
        json.dump(detailed_data, f, ensure_ascii=False, indent=2)
    print(f"âœ“ è¯¦ç»†å‘é‡æ•°æ®: {detailed_file}")

    # 5. ç”Ÿæˆç®€è¦åˆ†ææŠ¥å‘Š
    report_file = os.path.join(year_output_dir, f"analysis_report.txt")
    with open(report_file, "w", encoding="utf-8") as f:
        f.write(f"{'='*60}\n")
        f.write(f"æ€§åˆ«-èŒä¸šEmbeddingåˆ†ææŠ¥å‘Š ({year}å¹´)\n")
        f.write(f"{'='*60}\n\n")

        f.write(f"åˆ†æçœä»½æ•°: {len(results)}\n")
        f.write(f"åˆ†æèŒä¸šæ•°: {len(ALL_OCCUPATIONS)}\n\n")

        f.write(f"{'='*60}\n")
        f.write(f"å„çœä»½æ€§åˆ«éš”ç¦»æŒ‡æ•°æ’åï¼ˆä½™å¼¦ç›¸ä¼¼åº¦å·®å€¼æ–¹æ³•ï¼ŒæŒ‰æ ‡å‡†å·®ï¼‰:\n")
        f.write(f"{'='*60}\n")
        stats_sorted = sorted(province_stats, key=lambda x: x["std_bias"], reverse=True)
        for i, stat in enumerate(stats_sorted, 1):
            f.write(
                f"{i:2d}. {stat['province']:10s} | "
                f"éš”ç¦»æŒ‡æ•°: {stat['std_bias']:.3f} | "
                f"å¹³å‡åå‘: {stat['mean_bias']:+.3f}\n"
            )

        f.write(f"\n{'='*60}\n")
        f.write(f"å„çœä»½æ€§åˆ«éš”ç¦»æŒ‡æ•°æ’åï¼ˆæ€§åˆ«è½´æŠ•å½±æ–¹æ³•ï¼ŒæŒ‰æ ‡å‡†å·®ï¼‰:\n")
        f.write(f"{'='*60}\n")
        stats_sorted_proj = sorted(
            province_stats, key=lambda x: x.get("std_projection", 0), reverse=True
        )
        for i, stat in enumerate(stats_sorted_proj, 1):
            f.write(
                f"{i:2d}. {stat['province']:10s} | "
                f"éš”ç¦»æŒ‡æ•°: {stat.get('std_projection', 0):.3f} | "
                f"å¹³å‡æŠ•å½±: {stat.get('mean_projection', 0):+.3f}\n"
            )

        f.write(f"\n{'='*60}\n")
        f.write(f"èŒä¸šæ€§åˆ«åå‘ä¸€è‡´æ€§åˆ†æ:\n")
        f.write(f"{'='*60}\n")

        # è®¡ç®—æ¯ä¸ªèŒä¸šåœ¨å„çœä»½çš„å¹³å‡åå‘
        occupation_avg = (
            occupation_df.groupby("occupation")["bias_score"]
            .agg(["mean", "std"])
            .sort_values("mean", ascending=False)
        )

        f.write(f"\næœ€åå¥³æ€§çš„èŒä¸šï¼ˆè·¨çœä»½å¹³å‡ï¼‰:\n")
        for i, (occ, row) in enumerate(occupation_avg.head(10).iterrows(), 1):
            f.write(
                f"  {i:2d}. {occ:15s} | å¹³å‡: {row['mean']:+.3f} | æ ‡å‡†å·®: {row['std']:.3f}\n"
            )

        f.write(f"\næœ€åç”·æ€§çš„èŒä¸šï¼ˆè·¨çœä»½å¹³å‡ï¼‰:\n")
        for i, (occ, row) in enumerate(
            occupation_avg.tail(10).iloc[::-1].iterrows(), 1
        ):
            f.write(
                f"  {i:2d}. {occ:15s} | å¹³å‡: {row['mean']:+.3f} | æ ‡å‡†å·®: {row['std']:.3f}\n"
            )

        f.write(f"\nèŒä¸šåå‘å·®å¼‚æœ€å¤§çš„ï¼ˆè·¨çœä»½æ ‡å‡†å·®æœ€å¤§ï¼‰:\n")
        occupation_var = occupation_avg.sort_values("std", ascending=False)
        for i, (occ, row) in enumerate(occupation_var.head(10).iterrows(), 1):
            f.write(
                f"  {i:2d}. {occ:15s} | å¹³å‡: {row['mean']:+.3f} | æ ‡å‡†å·®: {row['std']:.3f}\n"
            )

        # æ·»åŠ æ€§åˆ«è½´æŠ•å½±æ–¹æ³•åˆ†æ
        f.write(f"\n{'='*60}\n")
        f.write(f"èŒä¸šæ€§åˆ«åå‘åˆ†æï¼ˆæ€§åˆ«è½´æŠ•å½±æ–¹æ³•ï¼‰:\n")
        f.write(f"{'='*60}\n")

        # è®¡ç®—æ¯ä¸ªèŒä¸šåœ¨å„çœä»½çš„å¹³å‡æŠ•å½±åˆ†æ•°
        occupation_proj_avg = (
            occupation_df.groupby("occupation")["projection_score"]
            .agg(["mean", "std"])
            .sort_values("mean", ascending=False)
        )

        f.write(f"\næœ€åå¥³æ€§çš„èŒä¸šï¼ˆè·¨çœä»½å¹³å‡ï¼ŒæŒ‰æŠ•å½±åˆ†æ•°ï¼‰:\n")
        for i, (occ, row) in enumerate(occupation_proj_avg.head(10).iterrows(), 1):
            f.write(
                f"  {i:2d}. {occ:15s} | å¹³å‡æŠ•å½±: {row['mean']:+.3f} | æ ‡å‡†å·®: {row['std']:.3f}\n"
            )

        f.write(f"\næœ€åç”·æ€§çš„èŒä¸šï¼ˆè·¨çœä»½å¹³å‡ï¼ŒæŒ‰æŠ•å½±åˆ†æ•°ï¼‰:\n")
        for i, (occ, row) in enumerate(
            occupation_proj_avg.tail(10).iloc[::-1].iterrows(), 1
        ):
            f.write(
                f"  {i:2d}. {occ:15s} | å¹³å‡æŠ•å½±: {row['mean']:+.3f} | æ ‡å‡†å·®: {row['std']:.3f}\n"
            )

        f.write(f"\nèŒä¸šæŠ•å½±å·®å¼‚æœ€å¤§çš„ï¼ˆè·¨çœä»½æ ‡å‡†å·®æœ€å¤§ï¼‰:\n")
        occupation_proj_var = occupation_proj_avg.sort_values("std", ascending=False)
        for i, (occ, row) in enumerate(occupation_proj_var.head(10).iterrows(), 1):
            f.write(
                f"  {i:2d}. {occ:15s} | å¹³å‡æŠ•å½±: {row['mean']:+.3f} | æ ‡å‡†å·®: {row['std']:.3f}\n"
            )

        # æ·»åŠ å®¶åŠ¡åˆ†å·¥åœºåŸŸåˆ†æ
        if domestic_work_data:
            f.write(f"\n{'='*60}\n")
            f.write(f"å®¶åŠ¡åˆ†å·¥åœºåŸŸåˆ†æï¼ˆå®¶åº­åœºåŸŸ vs å·¥ä½œåœºåŸŸï¼‰:\n")
            f.write(f"{'='*60}\n")

            domestic_work_df = pd.DataFrame(domestic_work_data)

            # è®¡ç®—æ¯ä¸ªçœä»½çš„æ€§åˆ«åœºåŸŸå·®å¼‚
            province_domain_gaps = []
            for province in domestic_work_df["province"].unique():
                prov_df = domestic_work_df[domestic_work_df["province"] == province]
                male_bias = prov_df[prov_df["word_type"] == "male"][
                    "domain_bias"
                ].values
                female_bias = prov_df[prov_df["word_type"] == "female"][
                    "domain_bias"
                ].values

                if len(male_bias) > 0 and len(female_bias) > 0:
                    gap = female_bias[0] - male_bias[0]
                    province_domain_gaps.append(
                        {"province": province, "gender_domain_gap": gap}
                    )

            if province_domain_gaps:
                province_gaps_df = pd.DataFrame(province_domain_gaps)
                province_gaps_df = province_gaps_df.sort_values(
                    "gender_domain_gap", ascending=False
                )

                f.write(f"\nå„çœä»½æ€§åˆ«åœ¨å®¶åº­åœºåŸŸ vs å·¥ä½œåœºåŸŸçš„å·®å¼‚æ’å:\n")
                f.write(f"(æ­£å€¼è¡¨ç¤ºå¥³æ€§æ›´åå‘å®¶åº­åœºåŸŸï¼Œè´Ÿå€¼è¡¨ç¤ºç”·æ€§æ›´åå‘å®¶åº­åœºåŸŸ)\n")
                for i, row in enumerate(province_gaps_df.itertuples(), 1):
                    f.write(
                        f"  {i:2d}. {row.province:10s} | æ€§åˆ«åœºåŸŸå·®å¼‚: {row.gender_domain_gap:+.3f}\n"
                    )

            # è®¡ç®—è·¨çœä»½å¹³å‡
            male_avg = domestic_work_df[domestic_work_df["word_type"] == "male"][
                "domain_bias"
            ].mean()
            female_avg = domestic_work_df[domestic_work_df["word_type"] == "female"][
                "domain_bias"
            ].mean()
            f.write(f"\nè·¨çœä»½å¹³å‡åœºåŸŸåå‘:\n")
            f.write(f"  ç”·æ€§: {male_avg:+.3f}\n")
            f.write(f"  å¥³æ€§: {female_avg:+.3f}\n")
            f.write(f"  æ€§åˆ«å·®å¼‚: {female_avg - male_avg:+.3f}\n")

    print(f"âœ“ åˆ†ææŠ¥å‘Š: {report_file}")

    print(f"\nâœ… æ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ° {year_output_dir}/ ç›®å½•")


def main(year: int, province: str = None):
    """
    è¿è¡Œembeddingåˆ†æ

    Args:
        year: å¹´ä»½
        province: æŒ‡å®šçœä»½ï¼ˆå¯é€‰ï¼‰ï¼Œå¦‚æœä¸æŒ‡å®šåˆ™åˆ†ææ‰€æœ‰çœä»½
    """
    print(f"\n{'='*60}")
    print(f"ğŸš€ å¼€å§‹åˆ†æ {year} å¹´æ•°æ®çš„æ€§åˆ«-èŒä¸šEmbedding")
    print(f"{'='*60}\n")

    # åŠ è½½æ¨¡å‹
    models = load_models(year, province)
    if not models:
        print("âŒ æ— æ³•åŠ è½½æ¨¡å‹")
        return

    # åˆ†ææ¨¡å‹
    results, province_stats = analyze_all_models(models)

    # ä¿å­˜ç»“æœ
    save_results(results, province_stats, year)

    print(f"\n{'='*60}")
    print(f"ğŸ‰ {year} å¹´embeddingåˆ†æå®Œæˆï¼")
    print(f"{'='*60}\n")


if __name__ == "__main__":
    fire.Fire(main)
