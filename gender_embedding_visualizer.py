"""
çœä»½æ€§åˆ«-èŒä¸šåå‘å¯è§†åŒ–åˆ†æï¼ˆä½¿ç”¨geopandasç»˜åˆ¶åœ°å›¾ï¼‰

åŠŸèƒ½ï¼š
1. çœä»½æ€§åˆ«éš”ç¦»ç¨‹åº¦åœ°å›¾ï¼ˆä½¿ç”¨geopandasï¼‰
2. çœä»½èšç±»åˆ†æï¼ˆåŸºäºèŒä¸šæ€§åˆ«åå‘æ¨¡å¼ï¼‰
3. ç‰¹å®šèŒä¸šçš„çœä»½å·®å¼‚å¯¹æ¯”
4. çœä»½é—´æ¨¡å¼ç›¸ä¼¼åº¦åˆ†æ

è¾“å…¥æ•°æ®ï¼šembedding_analysis/ ç›®å½•ä¸‹çš„åˆ†æç»“æœ
"""

import os
import glob
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import geopandas as gpd
from matplotlib.font_manager import FontProperties
from matplotlib.colors import LinearSegmentedColormap
import warnings

warnings.filterwarnings("ignore")

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams["font.sans-serif"] = ["SimHei", "DejaVu Sans"]
plt.rcParams["axes.unicode_minus"] = False

try:
    plt.rcParams["font.sans-serif"] = [
        "Arial Unicode MS",
        "SimHei",
        "STHeiti",
        "Microsoft YaHei",
    ]
except:
    pass

INPUT_DIR = "embedding_analysis"
OUTPUT_DIR = "embedding_visualization"
os.makedirs(OUTPUT_DIR, exist_ok=True)

# çœä»½ç¼–ç æ˜ å°„ï¼ˆGB/T 2260 ä¸­åäººæ°‘å…±å’Œå›½è¡Œæ”¿åŒºåˆ’ä»£ç ï¼‰
# å¦‚æœanalyzerè¾“å‡ºçš„çœä»½æ˜¯ç¼–ç æ ¼å¼ï¼Œå°†ç¼–ç è½¬æ¢ä¸ºçœä»½åç§°
PROVINCE_CODE_TO_NAME = {
    "11": "åŒ—äº¬",
    "12": "å¤©æ´¥",
    "13": "æ²³åŒ—",
    "14": "å±±è¥¿",
    "15": "å†…è’™å¤",
    "21": "è¾½å®",
    "22": "å‰æ—",
    "23": "é»‘é¾™æ±Ÿ",
    "31": "ä¸Šæµ·",
    "32": "æ±Ÿè‹",
    "33": "æµ™æ±Ÿ",
    "34": "å®‰å¾½",
    "35": "ç¦å»º",
    "36": "æ±Ÿè¥¿",
    "37": "å±±ä¸œ",
    "41": "æ²³å—",
    "42": "æ¹–åŒ—",
    "43": "æ¹–å—",
    "44": "å¹¿ä¸œ",
    "45": "å¹¿è¥¿",
    "46": "æµ·å—",
    "50": "é‡åº†",
    "51": "å››å·",
    "52": "è´µå·",
    "53": "äº‘å—",
    "54": "è¥¿è—",
    "61": "é™•è¥¿",
    "62": "ç”˜è‚ƒ",
    "63": "é’æµ·",
    "64": "å®å¤",
    "65": "æ–°ç–†",
    "71": "å°æ¹¾",
    "81": "é¦™æ¸¯",
    "82": "æ¾³é—¨",
    # å¤„ç†å¯èƒ½çš„éæ ‡å‡†ç¼–ç 
    "100": "æœªçŸ¥",
    "400": "æœªçŸ¥",
}

# çœä»½åç§°æ ‡å‡†åŒ–æ˜ å°„ï¼ˆå¤„ç†shapefileä¸­çš„å‘½åå·®å¼‚ï¼‰
PROVINCE_NAME_MAPPING = {
    "åŒ—äº¬": "åŒ—äº¬å¸‚",
    "å¤©æ´¥": "å¤©æ´¥å¸‚",
    "ä¸Šæµ·": "ä¸Šæµ·å¸‚",
    "é‡åº†": "é‡åº†å¸‚",
    "æ²³åŒ—": "æ²³åŒ—çœ",
    "å±±è¥¿": "å±±è¥¿çœ",
    "è¾½å®": "è¾½å®çœ",
    "å‰æ—": "å‰æ—çœ",
    "é»‘é¾™æ±Ÿ": "é»‘é¾™æ±Ÿçœ",
    "æ±Ÿè‹": "æ±Ÿè‹çœ",
    "æµ™æ±Ÿ": "æµ™æ±Ÿçœ",
    "å®‰å¾½": "å®‰å¾½çœ",
    "ç¦å»º": "ç¦å»ºçœ",
    "æ±Ÿè¥¿": "æ±Ÿè¥¿çœ",
    "å±±ä¸œ": "å±±ä¸œçœ",
    "æ²³å—": "æ²³å—çœ",
    "æ¹–åŒ—": "æ¹–åŒ—çœ",
    "æ¹–å—": "æ¹–å—çœ",
    "å¹¿ä¸œ": "å¹¿ä¸œçœ",
    "æµ·å—": "æµ·å—çœ",
    "å››å·": "å››å·çœ",
    "è´µå·": "è´µå·çœ",
    "äº‘å—": "äº‘å—çœ",
    "é™•è¥¿": "é™•è¥¿çœ",
    "ç”˜è‚ƒ": "ç”˜è‚ƒçœ",
    "é’æµ·": "é’æµ·çœ",
    "å°æ¹¾": "å°æ¹¾çœ",
    "å†…è’™å¤": "å†…è’™å¤è‡ªæ²»åŒº",
    "å¹¿è¥¿": "å¹¿è¥¿å£®æ—è‡ªæ²»åŒº",
    "è¥¿è—": "è¥¿è—è‡ªæ²»åŒº",
    "å®å¤": "å®å¤å›æ—è‡ªæ²»åŒº",
    "æ–°ç–†": "æ–°ç–†ç»´å¾å°”è‡ªæ²»åŒº",
    "é¦™æ¸¯": "é¦™æ¸¯ç‰¹åˆ«è¡Œæ”¿åŒº",
    "æ¾³é—¨": "æ¾³é—¨ç‰¹åˆ«è¡Œæ”¿åŒº",
}

# çœä»½åˆ°åœ°ç†åŒºåŸŸçš„æ˜ å°„
PROVINCE_REGIONS = {
    "ååŒ—": ["åŒ—äº¬", "å¤©æ´¥", "æ²³åŒ—", "å±±è¥¿", "å†…è’™å¤"],
    "ä¸œåŒ—": ["è¾½å®", "å‰æ—", "é»‘é¾™æ±Ÿ"],
    "åä¸œ": ["ä¸Šæµ·", "æ±Ÿè‹", "æµ™æ±Ÿ", "å®‰å¾½", "ç¦å»º", "æ±Ÿè¥¿", "å±±ä¸œ"],
    "åä¸­": ["æ²³å—", "æ¹–åŒ—", "æ¹–å—"],
    "åå—": ["å¹¿ä¸œ", "å¹¿è¥¿", "æµ·å—"],
    "è¥¿å—": ["é‡åº†", "å››å·", "è´µå·", "äº‘å—", "è¥¿è—"],
    "è¥¿åŒ—": ["é™•è¥¿", "ç”˜è‚ƒ", "é’æµ·", "å®å¤", "æ–°ç–†"],
}

PROVINCE_TO_REGION = {}
for region, provinces in PROVINCE_REGIONS.items():
    for province in provinces:
        PROVINCE_TO_REGION[province] = region


def load_results(year):
    """åŠ è½½åˆ†æç»“æœ"""
    stats_file = os.path.join(INPUT_DIR, f"province_stats_{year}.csv")
    occupation_file = os.path.join(INPUT_DIR, f"occupation_bias_{year}.csv")

    if not os.path.exists(stats_file) or not os.path.exists(occupation_file):
        print(f"âŒ æœªæ‰¾åˆ° {year} å¹´çš„åˆ†æç»“æœ")
        return None, None

    stats_df = pd.read_csv(stats_file)
    occupation_df = pd.read_csv(occupation_file)

    # å°†çœä»½ç¼–ç è½¬æ¢ä¸ºçœä»½åç§°ï¼ˆå¦‚æœanalyzerè¾“å‡ºçš„æ˜¯ç¼–ç æ ¼å¼ï¼‰
    def convert_province_code(province):
        """å°†çœä»½ç¼–ç è½¬æ¢ä¸ºçœä»½åç§°"""
        if pd.isna(province):
            return province
        # ç»Ÿä¸€è½¬æ¢ä¸ºå­—ç¬¦ä¸²æ ¼å¼å¤„ç†
        if isinstance(province, (int, float)):
            code_str = str(int(province))  # å»æ‰å°æ•°ç‚¹
        else:
            code_str = str(province).strip()

        # å¦‚æœæ˜¯ç¼–ç ï¼Œè½¬æ¢ä¸ºåç§°
        if code_str in PROVINCE_CODE_TO_NAME:
            return PROVINCE_CODE_TO_NAME[code_str]
        # å¦‚æœå·²ç»æ˜¯åç§°ï¼Œç›´æ¥è¿”å›
        elif code_str in PROVINCE_TO_REGION:
            return code_str
        # å¦‚æœéƒ½ä¸åŒ¹é…ï¼Œè¿”å›åŸå€¼
        return code_str

    # è½¬æ¢çœä»½ç¼–ç 
    print(f"  æ­£åœ¨æ£€æŸ¥å¹¶è½¬æ¢çœä»½ç¼–ç ...")
    original_provinces = set(stats_df["province"].unique())

    # ç»Ÿè®¡æœ‰å¤šå°‘æ˜¯ç¼–ç æ ¼å¼
    code_count = sum(
        1 for p in original_provinces if str(p).strip() in PROVINCE_CODE_TO_NAME
    )
    name_count = len(original_provinces) - code_count

    if code_count > 0:
        print(f"  å‘ç° {code_count} ä¸ªç¼–ç æ ¼å¼çš„çœä»½ï¼Œ{name_count} ä¸ªåç§°æ ¼å¼çš„çœä»½")

    stats_df["province"] = stats_df["province"].apply(convert_province_code)
    occupation_df["province"] = occupation_df["province"].apply(convert_province_code)

    # æ£€æŸ¥è½¬æ¢ç»“æœ
    unique_provinces = stats_df["province"].unique()
    print(
        f"  è½¬æ¢åçš„çœä»½: {', '.join(sorted(unique_provinces)[:15])}{'...' if len(unique_provinces) > 15 else ''}"
    )

    # æ£€æŸ¥æ˜¯å¦æœ‰æœªè¯†åˆ«çš„çœä»½
    unknown_provinces = [p for p in unique_provinces if p not in PROVINCE_TO_REGION]
    if unknown_provinces:
        print(f"  âš ï¸  ä»¥ä¸‹çœä»½æœªåœ¨åŒºåŸŸæ˜ å°„ä¸­æ‰¾åˆ°: {', '.join(unknown_provinces)}")
        print(f"     è¿™äº›çœä»½å¯èƒ½æ¥è‡ªéæ ‡å‡†ç¼–ç ï¼Œå°†æ ‡è®°ä¸º'æœªçŸ¥åŒºåŸŸ'")

    # æ·»åŠ åœ°ç†åŒºåŸŸä¿¡æ¯
    stats_df["region"] = stats_df["province"].map(PROVINCE_TO_REGION)
    occupation_df["region"] = occupation_df["province"].map(PROVINCE_TO_REGION)

    # å¤„ç†æœªè¯†åˆ«çš„çœä»½
    stats_df["region"] = stats_df["region"].fillna("æœªçŸ¥åŒºåŸŸ")
    occupation_df["region"] = occupation_df["region"].fillna("æœªçŸ¥åŒºåŸŸ")

    print(f"âœ“ åŠ è½½äº† {len(stats_df)} ä¸ªçœä»½çš„æ•°æ®")
    print(f"âœ“ åŠ è½½äº† {len(occupation_df)} æ¡èŒä¸š-çœä»½è®°å½•")

    return stats_df, occupation_df


def load_china_map(shapefile_path=None):
    """
    åŠ è½½ä¸­å›½åœ°å›¾shapefile

    Args:
        shapefile_path: shapefileè·¯å¾„æˆ–æ–‡ä»¶å¤¹è·¯å¾„ï¼ˆå¦‚æœä¸ºNoneï¼Œè‡ªåŠ¨æŸ¥æ‰¾configs/china_shpæ–‡ä»¶å¤¹ï¼‰

    Returns:
        GeoDataFrame æˆ– Noneï¼ˆå¦‚æœåŠ è½½å¤±è´¥ï¼‰
    """
    # å¦‚æœæ²¡æœ‰æŒ‡å®šè·¯å¾„ï¼Œå°è¯•ä»configs/china_shpæ–‡ä»¶å¤¹åŠ è½½
    if shapefile_path is None:
        shapefile_dir = "configs/china_shp"
        if os.path.exists(shapefile_dir) and os.path.isdir(shapefile_dir):
            # æŸ¥æ‰¾æ–‡ä»¶å¤¹ä¸­çš„.shpæ–‡ä»¶
            shp_files = glob.glob(os.path.join(shapefile_dir, "*.shp"))
            if shp_files:
                shapefile_path = shp_files[0]  # ä½¿ç”¨æ‰¾åˆ°çš„ç¬¬ä¸€ä¸ª.shpæ–‡ä»¶
                print(f"è‡ªåŠ¨æ‰¾åˆ°åœ°å›¾æ–‡ä»¶: {shapefile_path}")
            else:
                print(f"âš ï¸  åœ¨ {shapefile_dir} ä¸­æœªæ‰¾åˆ°.shpæ–‡ä»¶")
                return None
        else:
            print(f"âš ï¸  åœ°å›¾æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {shapefile_dir}")
            return None

    # å¦‚æœæ˜¯æ–‡ä»¶å¤¹è·¯å¾„ï¼ŒæŸ¥æ‰¾å…¶ä¸­çš„.shpæ–‡ä»¶
    if os.path.isdir(shapefile_path):
        shp_files = glob.glob(os.path.join(shapefile_path, "*.shp"))
        if shp_files:
            shapefile_path = shp_files[0]
        else:
            print(f"âš ï¸  åœ¨ {shapefile_path} ä¸­æœªæ‰¾åˆ°.shpæ–‡ä»¶")
            return None

    if not os.path.exists(shapefile_path):
        print(f"âš ï¸  åœ°å›¾æ–‡ä»¶ä¸å­˜åœ¨: {shapefile_path}")
        return None

    try:
        print(f"æ­£åœ¨åŠ è½½åœ°å›¾æ–‡ä»¶: {shapefile_path}")
        gdf = gpd.read_file(shapefile_path)

        if gdf.empty:
            print(f"âš ï¸  åœ°å›¾æ–‡ä»¶ä¸ºç©º")
            return None

        print(f"âœ“ æˆåŠŸåŠ è½½ï¼ŒåŒ…å« {len(gdf)} ä¸ªåœ°ç†è¦ç´ ")
        print(f"  åœ°å›¾åˆ—å: {gdf.columns.tolist()}")

        # ç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„CRS
        if gdf.crs is None:
            gdf = gdf.set_crs("EPSG:4326", allow_override=True)

        return gdf

    except Exception as e:
        print(f"âŒ åŠ è½½åœ°å›¾æ–‡ä»¶å¤±è´¥: {e}")
        return None


def plot_china_map_segregation(stats_df, year, shapefile_path=None):
    """
    ä½¿ç”¨geopandasç»˜åˆ¶ä¸­å›½åœ°å›¾ï¼šå±•ç¤ºå„çœä»½çš„æ€§åˆ«éš”ç¦»ç¨‹åº¦

    Args:
        stats_df: çœä»½ç»Ÿè®¡æ•°æ®
        year: å¹´ä»½
        shapefile_path: ä¸­å›½åœ°å›¾shapefileè·¯å¾„ï¼ˆå¯é€‰ï¼‰
    """
    # åŠ è½½åœ°å›¾ï¼ˆè‡ªåŠ¨ä»configs/china_shpæ–‡ä»¶å¤¹åŠ è½½ï¼‰
    china_map = load_china_map(shapefile_path)

    if china_map is None:
        print("âŒ æ— æ³•åŠ è½½åœ°å›¾æ–‡ä»¶ï¼Œè·³è¿‡åœ°å›¾ç»˜åˆ¶")
        print("   å°†ç»˜åˆ¶æ›¿ä»£å›¾è¡¨...")
        plot_static_alternatives(stats_df, year)
        return

    # æ‰“å°shapefileçš„åˆ—åï¼Œå¸®åŠ©è°ƒè¯•
    print(f"  Shapefileåˆ—å: {china_map.columns.tolist()}")

    # è‡ªåŠ¨è¯†åˆ«çœä»½åç§°åˆ—ï¼ˆhumdata adm1æ•°æ®é€šå¸¸ä½¿ç”¨ADMIN1æˆ–NAME_1ï¼‰
    possible_name_cols = [
        "ADMIN1",  # humdataæ ‡å‡†åˆ—å
        "admin1",
        "NAME_1",  # humdataå¸¸ç”¨åˆ—å
        "name_1",
        "NAME",  # å…¶ä»–å¯èƒ½çš„åˆ—å
        "name",
        "PROV",
        "prov",
        "Province",
        "province",
        "NAME_CH",
        "name_ch",
        "FCNAME",  # ä¸­æ–‡åç§°
        "fcname",
    ]
    name_col = None
    for col in possible_name_cols:
        if col in china_map.columns:
            name_col = col
            break

    if name_col is None:
        print(f"âš ï¸  æ— æ³•è‡ªåŠ¨è¯†åˆ«çœä»½åç§°åˆ—ï¼Œè¯·æ‰‹åŠ¨æŒ‡å®š")
        print(f"   å¯ç”¨åˆ—: {china_map.columns.tolist()}")
        return

    print(f"  ä½¿ç”¨çœä»½åç§°åˆ—: {name_col}")

    # æ ‡å‡†åŒ–çœä»½åç§°
    stats_df_copy = stats_df.copy()
    stats_df_copy["province_full"] = stats_df_copy["province"].map(
        PROVINCE_NAME_MAPPING
    )

    # å¦‚æœmappingåè¿˜æ˜¯Noneï¼Œè¯´æ˜å°±æ˜¯åŸå
    stats_df_copy["province_full"] = stats_df_copy["province_full"].fillna(
        stats_df_copy["province"]
    )

    # åˆå¹¶æ•°æ®
    china_map_merged = china_map.merge(
        stats_df_copy, left_on=name_col, right_on="province_full", how="left"
    )

    # æ£€æŸ¥åˆå¹¶æƒ…å†µ
    matched = china_map_merged["std_bias"].notna().sum()
    total_provinces = len(stats_df)
    print(f"  åœ°å›¾åŒ¹é…: {matched}/{total_provinces} ä¸ªçœä»½")

    if matched == 0:
        print("âš ï¸  æ²¡æœ‰åŒ¹é…åˆ°ä»»ä½•çœä»½ï¼Œå¯èƒ½æ˜¯å‘½åä¸ä¸€è‡´")
        print(f"  åœ°å›¾ä¸­çš„çœä»½åç§°ç¤ºä¾‹: {china_map[name_col].head().tolist()}")
        print(
            f"  æ•°æ®ä¸­çš„çœä»½åç§°ç¤ºä¾‹: {stats_df_copy['province_full'].head().tolist()}"
        )
        return

    # ç»˜åˆ¶åœ°å›¾
    fig, ax = plt.subplots(1, 1, figsize=(16, 12))

    # è‡ªå®šä¹‰é…è‰²æ–¹æ¡ˆï¼ˆç™½è‰²->æ©™è‰²->çº¢è‰²->æ·±çº¢è‰²ï¼‰
    colors = [
        "#fff5f0",
        "#fee5d9",
        "#fcbba1",
        "#fc9272",
        "#fb6a4a",
        "#ef3b2c",
        "#cb181d",
        "#99000d",
    ]
    cmap = LinearSegmentedColormap.from_list("segregation", colors)

    # ç»˜åˆ¶æœ‰æ•°æ®çš„çœä»½
    china_map_merged.plot(
        column="std_bias",
        cmap=cmap,
        linewidth=0.5,
        edgecolor="white",
        legend=True,
        ax=ax,
        missing_kwds={"color": "lightgrey", "label": "æ— æ•°æ®"},
        legend_kwds={
            "label": "æ€§åˆ«éš”ç¦»æŒ‡æ•°ï¼ˆæ ‡å‡†å·®ï¼‰",
            "orientation": "vertical",
            "shrink": 0.6,
            "pad": 0.05,
        },
    )

    # æ·»åŠ çœä»½æ ‡ç­¾ï¼ˆåªæ ‡æ³¨æœ‰æ•°æ®çš„çœä»½ï¼‰
    for idx, row in china_map_merged.iterrows():
        if pd.notna(row["std_bias"]):
            # è·å–çœä»½ä¸­å¿ƒç‚¹
            centroid = row["geometry"].centroid

            # æ ‡æ³¨çœä»½åç§°å’Œæ•°å€¼
            ax.annotate(
                text=f"{row['province']}\n{row['std_bias']:.3f}",
                xy=(centroid.x, centroid.y),
                ha="center",
                va="center",
                fontsize=8,
                fontweight="bold",
                color="black",
                bbox=dict(
                    boxstyle="round,pad=0.3",
                    facecolor="white",
                    alpha=0.7,
                    edgecolor="none",
                ),
            )

    ax.set_title(
        f"ä¸­å›½å„çœä»½èŒä¸šæ€§åˆ«éš”ç¦»ç¨‹åº¦åœ°å›¾ ({year}å¹´)\n"
        + "é¢œè‰²è¶Šæ·± = æ€§åˆ«éš”ç¦»ç¨‹åº¦è¶Šé«˜ï¼ˆèŒä¸šæ€§åˆ«åˆ†åŒ–è¶Šæ˜æ˜¾ï¼‰",
        fontsize=16,
        fontweight="bold",
        pad=20,
    )
    ax.axis("off")

    # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯æ–‡æœ¬æ¡†
    stats_text = (
        f"åˆ†æçœä»½æ•°: {total_provinces}\n"
        f"æœ€é«˜: {stats_df.nlargest(1, 'std_bias')['province'].values[0]} ({stats_df['std_bias'].max():.3f})\n"
        f"æœ€ä½: {stats_df.nsmallest(1, 'std_bias')['province'].values[0]} ({stats_df['std_bias'].min():.3f})\n"
        f"å¹³å‡: {stats_df['std_bias'].mean():.3f}"
    )
    ax.text(
        0.02,
        0.98,
        stats_text,
        transform=ax.transAxes,
        fontsize=10,
        verticalalignment="top",
        bbox=dict(boxstyle="round", facecolor="wheat", alpha=0.8),
    )

    plt.tight_layout()
    map_file = os.path.join(OUTPUT_DIR, f"segregation_map_{year}.pdf")
    plt.savefig(map_file, format="pdf", bbox_inches="tight")
    print(f"âœ“ ä¸­å›½åœ°å›¾å·²ä¿å­˜: {map_file}")
    plt.close()

    # ç»˜åˆ¶ç¬¬äºŒå¼ åœ°å›¾ï¼šæŒ‰åŒºåŸŸç€è‰²
    plot_regional_map(china_map, china_map_merged, stats_df, year, name_col)


def plot_regional_map(china_map, china_map_merged, stats_df, year, name_col):
    """ç»˜åˆ¶æŒ‰åœ°ç†åŒºåŸŸç€è‰²çš„åœ°å›¾"""
    fig, ax = plt.subplots(1, 1, figsize=(16, 12))

    # ä¸ºæ¯ä¸ªåŒºåŸŸåˆ†é…é¢œè‰²
    region_colors = {
        "ååŒ—": "#e41a1c",
        "ä¸œåŒ—": "#377eb8",
        "åä¸œ": "#4daf4a",
        "åä¸­": "#984ea3",
        "åå—": "#ff7f00",
        "è¥¿å—": "#ffff33",
        "è¥¿åŒ—": "#a65628",
    }

    # æ·»åŠ åŒºåŸŸé¢œè‰²åˆ°åœ°å›¾æ•°æ®
    china_map_merged["region_color"] = china_map_merged["region"].map(region_colors)

    # ç»˜åˆ¶åœ°å›¾
    china_map_merged.plot(
        color=china_map_merged["region_color"].fillna("lightgrey"),
        linewidth=0.5,
        edgecolor="white",
        ax=ax,
        alpha=0.6,
    )

    # æ·»åŠ çœä»½æ ‡ç­¾å’Œæ•°å€¼
    for idx, row in china_map_merged.iterrows():
        if pd.notna(row["std_bias"]):
            centroid = row["geometry"].centroid
            ax.annotate(
                text=f"{row['province']}\n{row['std_bias']:.3f}",
                xy=(centroid.x, centroid.y),
                ha="center",
                va="center",
                fontsize=8,
                fontweight="bold",
                color="black",
                bbox=dict(
                    boxstyle="round,pad=0.3",
                    facecolor="white",
                    alpha=0.9,
                    edgecolor="none",
                ),
            )

    ax.set_title(
        f"ä¸­å›½å„çœä»½æ€§åˆ«éš”ç¦»ç¨‹åº¦ï¼šæŒ‰åœ°ç†åŒºåŸŸåˆ†ç±» ({year}å¹´)",
        fontsize=16,
        fontweight="bold",
        pad=20,
    )
    ax.axis("off")

    # æ·»åŠ å›¾ä¾‹
    from matplotlib.patches import Patch

    legend_elements = [
        Patch(
            facecolor=color,
            label=f'{region} (å‡å€¼: {stats_df[stats_df["region"]==region]["std_bias"].mean():.3f})',
        )
        for region, color in region_colors.items()
        if region in stats_df["region"].values
    ]
    ax.legend(
        handles=legend_elements,
        loc="lower left",
        fontsize=10,
        title="åœ°ç†åŒºåŸŸ",
        title_fontsize=11,
        framealpha=0.9,
    )

    plt.tight_layout()
    regional_map_file = os.path.join(OUTPUT_DIR, f"segregation_map_regional_{year}.pdf")
    plt.savefig(regional_map_file, format="pdf", bbox_inches="tight")
    print(f"âœ“ åŒºåŸŸåœ°å›¾å·²ä¿å­˜: {regional_map_file}")
    plt.close()


def plot_static_alternatives(stats_df, year):
    """å¦‚æœæ— æ³•åŠ è½½åœ°å›¾ï¼Œç»˜åˆ¶æ›¿ä»£å›¾è¡¨"""
    fig, ax = plt.subplots(1, 1, figsize=(14, 10))

    # æŒ‰åŒºåŸŸåˆ†ç»„
    region_data = []
    for region, provinces in PROVINCE_REGIONS.items():
        region_provinces = stats_df[stats_df["province"].isin(provinces)]
        if len(region_provinces) > 0:
            region_data.append(
                {
                    "region": region,
                    "mean_segregation": region_provinces["std_bias"].mean(),
                    "provinces": ", ".join(region_provinces["province"].tolist()),
                }
            )

    region_df = pd.DataFrame(region_data).sort_values(
        "mean_segregation", ascending=False
    )

    # ç»˜åˆ¶æŸ±çŠ¶å›¾
    colors = plt.cm.Reds(np.linspace(0.3, 0.9, len(region_df)))
    bars = ax.barh(region_df["region"], region_df["mean_segregation"], color=colors)

    for i, (bar, row) in enumerate(zip(bars, region_df.itertuples())):
        ax.text(
            bar.get_width() + 0.002,
            bar.get_y() + bar.get_height() / 2,
            f"{row.mean_segregation:.3f}",
            va="center",
            fontsize=10,
            fontweight="bold",
        )

    ax.set_xlabel("å¹³å‡æ€§åˆ«éš”ç¦»æŒ‡æ•°ï¼ˆæ ‡å‡†å·®ï¼‰", fontsize=12, fontweight="bold")
    ax.set_title(
        f"ä¸­å›½å„åœ°åŒºèŒä¸šæ€§åˆ«éš”ç¦»ç¨‹åº¦ ({year}å¹´)\næ•°å€¼è¶Šå¤§ = èŒä¸šæ€§åˆ«åˆ†åŒ–è¶Šæ˜æ˜¾",
        fontsize=14,
        fontweight="bold",
        pad=20,
    )
    ax.grid(axis="x", alpha=0.3, linestyle="--")

    plt.tight_layout()
    map_file = os.path.join(OUTPUT_DIR, f"segregation_by_region_{year}.pdf")
    plt.savefig(map_file, format="pdf", bbox_inches="tight")
    print(f"âœ“ åŒºåŸŸæŸ±çŠ¶å›¾å·²ä¿å­˜: {map_file}")
    plt.close()


def plot_province_ranking(stats_df, year):
    """ç»˜åˆ¶è¯¦ç»†çš„çœä»½æ’åå›¾"""
    fig, ax = plt.subplots(1, 1, figsize=(12, 10))
    stats_sorted = stats_df.sort_values("std_bias", ascending=True)

    # æŒ‰åŒºåŸŸç€è‰²
    colors = [
        plt.cm.Set3(
            list(PROVINCE_REGIONS.keys()).index(PROVINCE_TO_REGION.get(p, "ååŒ—")) / 7
        )
        for p in stats_sorted["province"]
    ]

    bars = ax.barh(stats_sorted["province"], stats_sorted["std_bias"], color=colors)

    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for bar in bars:
        width = bar.get_width()
        ax.text(
            width + 0.002,
            bar.get_y() + bar.get_height() / 2,
            f"{width:.3f}",
            va="center",
            fontsize=9,
        )

    ax.set_xlabel("æ€§åˆ«éš”ç¦»æŒ‡æ•°ï¼ˆæ ‡å‡†å·®ï¼‰", fontsize=12, fontweight="bold")
    ax.set_title(
        f"å„çœä»½èŒä¸šæ€§åˆ«éš”ç¦»ç¨‹åº¦æ’å ({year}å¹´)", fontsize=14, fontweight="bold", pad=20
    )
    ax.grid(axis="x", alpha=0.3, linestyle="--")

    # æ·»åŠ å›¾ä¾‹
    from matplotlib.patches import Patch

    legend_elements = [
        Patch(facecolor=plt.cm.Set3(i / 7), label=region)
        for i, region in enumerate(PROVINCE_REGIONS.keys())
    ]
    ax.legend(handles=legend_elements, loc="lower right", fontsize=9, title="åœ°ç†åŒºåŸŸ")

    plt.tight_layout()
    ranking_file = os.path.join(OUTPUT_DIR, f"segregation_ranking_{year}.pdf")
    plt.savefig(ranking_file, format="pdf", bbox_inches="tight")
    print(f"âœ“ çœä»½æ’åå›¾å·²ä¿å­˜: {ranking_file}")
    plt.close()


def plot_province_clustering(occupation_df, stats_df, year):
    """çœä»½èšç±»åˆ†æï¼šåŸºäºèŒä¸šæ€§åˆ«åå‘æ¨¡å¼"""
    from scipy.cluster.hierarchy import dendrogram, linkage
    from scipy.spatial.distance import pdist, squareform

    # åˆ›å»ºçœä»½Ã—èŒä¸šçŸ©é˜µ
    pivot = occupation_df.pivot_table(
        values="bias_score", index="province", columns="occupation", aggfunc="mean"
    ).fillna(0)

    # å±‚æ¬¡èšç±»
    linkage_matrix = linkage(pivot, method="ward")

    # ç»˜åˆ¶æ ‘çŠ¶å›¾
    fig, ax = plt.subplots(1, 1, figsize=(14, 8))

    dendrogram(
        linkage_matrix,
        labels=pivot.index.tolist(),
        leaf_font_size=11,
        ax=ax,
        color_threshold=0.7 * max(linkage_matrix[:, 2]),
    )

    ax.set_title(
        f"çœä»½æ€§åˆ«è§‚å¿µæ¨¡å¼èšç±»åˆ†æ ({year}å¹´)\nåŸºäºèŒä¸šæ€§åˆ«åå‘æ¨¡å¼çš„ç›¸ä¼¼åº¦",
        fontsize=14,
        fontweight="bold",
        pad=20,
    )
    ax.set_xlabel("çœä»½", fontsize=12, fontweight="bold")
    ax.set_ylabel("è·ç¦»ï¼ˆå·®å¼‚ç¨‹åº¦ï¼‰", fontsize=12, fontweight="bold")
    ax.grid(axis="y", alpha=0.3, linestyle="--")

    plt.tight_layout()
    cluster_file = os.path.join(OUTPUT_DIR, f"province_clustering_{year}.pdf")
    plt.savefig(cluster_file, format="pdf", bbox_inches="tight")
    print(f"âœ“ çœä»½èšç±»å›¾å·²ä¿å­˜: {cluster_file}")
    plt.close()

    # ç»˜åˆ¶çƒ­åŠ›å›¾ï¼šçœä»½ç›¸ä¼¼åº¦çŸ©é˜µ
    distances = pdist(pivot, metric="euclidean")
    distance_matrix = squareform(distances)

    # è½¬æ¢ä¸ºç›¸ä¼¼åº¦
    max_dist = distance_matrix.max()
    similarity_matrix = 1 - (distance_matrix / max_dist)

    fig, ax = plt.subplots(1, 1, figsize=(12, 10))

    sns.heatmap(
        similarity_matrix,
        xticklabels=pivot.index,
        yticklabels=pivot.index,
        annot=False,
        fmt=".2f",
        cmap="YlOrRd",
        cbar_kws={"label": "æ¨¡å¼ç›¸ä¼¼åº¦"},
        ax=ax,
        square=True,
    )

    ax.set_title(
        f"çœä»½æ€§åˆ«è§‚å¿µæ¨¡å¼ç›¸ä¼¼åº¦çŸ©é˜µ ({year}å¹´)\né¢œè‰²è¶Šæ·± = æ¨¡å¼è¶Šç›¸ä¼¼",
        fontsize=14,
        fontweight="bold",
        pad=20,
    )

    plt.tight_layout()
    similarity_file = os.path.join(OUTPUT_DIR, f"province_similarity_{year}.pdf")
    plt.savefig(similarity_file, format="pdf", bbox_inches="tight")
    print(f"âœ“ çœä»½ç›¸ä¼¼åº¦çŸ©é˜µå·²ä¿å­˜: {similarity_file}")
    plt.close()


def plot_province_comparison(stats_df, year):
    """çœä»½å¤šç»´åº¦å¯¹æ¯”å›¾"""
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))

    # 1. éš”ç¦»ç¨‹åº¦ vs å¹³å‡åå‘
    ax = axes[0, 0]
    scatter = ax.scatter(
        stats_df["mean_bias"],
        stats_df["std_bias"],
        s=stats_df["text_count"] / 1000,
        c=stats_df["std_bias"],
        cmap="Reds",
        alpha=0.6,
        edgecolors="black",
        linewidth=1,
    )

    for _, row in stats_df.iterrows():
        ax.annotate(
            row["province"],
            (row["mean_bias"], row["std_bias"]),
            fontsize=8,
            ha="center",
        )

    ax.axhline(
        y=stats_df["std_bias"].mean(),
        color="gray",
        linestyle="--",
        alpha=0.5,
        label="å¹³å‡éš”ç¦»ç¨‹åº¦",
    )
    ax.axvline(x=0, color="gray", linestyle="--", alpha=0.5, label="æ€§åˆ«ä¸­æ€§")

    ax.set_xlabel(
        "å¹³å‡æ€§åˆ«åå‘\n(è´Ÿ=åç”·æ€§, æ­£=åå¥³æ€§)", fontsize=11, fontweight="bold"
    )
    ax.set_ylabel(
        "æ€§åˆ«éš”ç¦»æŒ‡æ•°\n(æ ‡å‡†å·®ï¼Œå€¼è¶Šå¤§=éš”ç¦»è¶Šæ˜æ˜¾)", fontsize=11, fontweight="bold"
    )
    ax.set_title("çœä»½æ€§åˆ«è§‚å¿µäºŒç»´åˆ†å¸ƒ", fontsize=12, fontweight="bold")
    ax.grid(alpha=0.3)
    ax.legend(fontsize=9)

    # 2. éš”ç¦»ç¨‹åº¦æ’åï¼ˆTop 15ï¼‰
    ax = axes[0, 1]
    top_15 = stats_df.nlargest(15, "std_bias").sort_values("std_bias")
    colors = plt.cm.Reds(np.linspace(0.4, 0.9, len(top_15)))
    bars = ax.barh(top_15["province"], top_15["std_bias"], color=colors)

    for bar in bars:
        width = bar.get_width()
        ax.text(
            width + 0.002,
            bar.get_y() + bar.get_height() / 2,
            f"{width:.3f}",
            va="center",
            fontsize=9,
        )

    ax.set_xlabel("æ€§åˆ«éš”ç¦»æŒ‡æ•°", fontsize=11, fontweight="bold")
    ax.set_title("æ€§åˆ«éš”ç¦»æœ€æ˜æ˜¾çš„çœä»½ (Top 15)", fontsize=12, fontweight="bold")
    ax.grid(axis="x", alpha=0.3)

    # 3. æ•°æ®è´¨é‡åˆ†å¸ƒ
    ax = axes[1, 0]
    stats_sorted = stats_df.sort_values("text_count", ascending=False)
    bars = ax.bar(
        range(len(stats_sorted)),
        stats_sorted["text_count"] / 10000,
        color="steelblue",
        alpha=0.7,
    )
    ax.set_xticks(range(len(stats_sorted)))
    ax.set_xticklabels(stats_sorted["province"], rotation=45, ha="right", fontsize=9)
    ax.set_ylabel("æ–‡æœ¬æ•°é‡ï¼ˆä¸‡æ¡ï¼‰", fontsize=11, fontweight="bold")
    ax.set_title("å„çœä»½æ•°æ®é‡åˆ†å¸ƒ", fontsize=12, fontweight="bold")
    ax.grid(axis="y", alpha=0.3)

    # 4. åŒºåŸŸå¯¹æ¯”ç®±çº¿å›¾
    ax = axes[1, 1]
    region_order = ["ååŒ—", "ä¸œåŒ—", "åä¸œ", "åä¸­", "åå—", "è¥¿å—", "è¥¿åŒ—"]
    data_by_region = [
        stats_df[stats_df["region"] == r]["std_bias"].values
        for r in region_order
        if r in stats_df["region"].values
    ]
    labels_with_data = [r for r in region_order if r in stats_df["region"].values]

    bp = ax.boxplot(data_by_region, labels=labels_with_data, patch_artist=True)
    for patch, color in zip(
        bp["boxes"], plt.cm.Set3(np.linspace(0, 1, len(data_by_region)))
    ):
        patch.set_facecolor(color)

    ax.set_ylabel("æ€§åˆ«éš”ç¦»æŒ‡æ•°", fontsize=11, fontweight="bold")
    ax.set_title("å„åœ°ç†åŒºåŸŸæ€§åˆ«éš”ç¦»ç¨‹åº¦åˆ†å¸ƒ", fontsize=12, fontweight="bold")
    ax.grid(axis="y", alpha=0.3)
    plt.setp(ax.xaxis.get_majorticklabels(), rotation=45, ha="right")

    plt.tight_layout()
    comparison_file = os.path.join(OUTPUT_DIR, f"province_comparison_{year}.pdf")
    plt.savefig(comparison_file, format="pdf", bbox_inches="tight")
    print(f"âœ“ çœä»½å¯¹æ¯”å›¾å·²ä¿å­˜: {comparison_file}")
    plt.close()


def plot_occupation_by_province(occupation_df, occupation_name, year):
    """ç‰¹å®šèŒä¸šåœ¨å„çœä»½çš„æ€§åˆ«åå‘å¯¹æ¯”"""
    occ_data = occupation_df[occupation_df["occupation"] == occupation_name].copy()

    if len(occ_data) == 0:
        print(f"âš ï¸  æœªæ‰¾åˆ°èŒä¸š: {occupation_name}")
        return

    occ_data = occ_data.sort_values("bias_score")

    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))

    # å·¦å›¾ï¼šæ€§åˆ«åå‘åˆ†æ•°
    colors = ["#d62728" if x < 0 else "#2ca02c" for x in occ_data["bias_score"]]
    bars = ax1.barh(
        occ_data["province"], occ_data["bias_score"], color=colors, alpha=0.7
    )

    ax1.axvline(x=0, color="black", linestyle="--", linewidth=1)
    ax1.set_xlabel(
        "æ€§åˆ«åå‘åˆ†æ•°\n(è´Ÿ=åç”·æ€§, æ­£=åå¥³æ€§)", fontsize=11, fontweight="bold"
    )
    ax1.set_title(
        f'"{occupation_name}"çš„æ€§åˆ«å…³è”ï¼šå„çœä»½å·®å¼‚', fontsize=12, fontweight="bold"
    )
    ax1.grid(axis="x", alpha=0.3)

    for bar in bars:
        width = bar.get_width()
        ax1.text(
            width + (0.005 if width > 0 else -0.005),
            bar.get_y() + bar.get_height() / 2,
            f"{width:+.3f}",
            va="center",
            ha="left" if width > 0 else "right",
            fontsize=8,
        )

    # å³å›¾ï¼šç”·æ€§/å¥³æ€§ç›¸ä¼¼åº¦å¯¹æ¯”
    x = np.arange(len(occ_data))
    width = 0.35

    bars1 = ax2.barh(
        x - width / 2,
        occ_data["male_similarity"],
        width,
        label="ç”·æ€§ç›¸ä¼¼åº¦",
        color="#1f77b4",
        alpha=0.7,
    )
    bars2 = ax2.barh(
        x + width / 2,
        occ_data["female_similarity"],
        width,
        label="å¥³æ€§ç›¸ä¼¼åº¦",
        color="#ff7f0e",
        alpha=0.7,
    )

    ax2.set_yticks(x)
    ax2.set_yticklabels(occ_data["province"])
    ax2.set_xlabel("ä¸æ€§åˆ«è¯çš„ç›¸ä¼¼åº¦", fontsize=11, fontweight="bold")
    ax2.set_title(
        f'"{occupation_name}"ä¸æ€§åˆ«è¯çš„ç›¸ä¼¼åº¦åˆ†è§£', fontsize=12, fontweight="bold"
    )
    ax2.legend(fontsize=10)
    ax2.grid(axis="x", alpha=0.3)

    plt.tight_layout()
    occ_file = os.path.join(OUTPUT_DIR, f"occupation_{occupation_name}_{year}.pdf")
    plt.savefig(occ_file, format="pdf", bbox_inches="tight")
    print(f"âœ“ èŒä¸šåˆ†æå›¾å·²ä¿å­˜: {occ_file}")
    plt.close()


def generate_summary_report(stats_df, occupation_df, year):
    """ç”Ÿæˆå¯è§†åŒ–åˆ†ææ€»ç»“æŠ¥å‘Š"""
    report_file = os.path.join(OUTPUT_DIR, f"visualization_summary_{year}.txt")

    with open(report_file, "w", encoding="utf-8") as f:
        f.write(f"{'='*70}\n")
        f.write(f"çœä»½æ€§åˆ«-èŒä¸šåå‘å¯è§†åŒ–åˆ†ææ€»ç»“ ({year}å¹´)\n")
        f.write(f"{'='*70}\n\n")

        # 1. æ€§åˆ«éš”ç¦»ç¨‹åº¦æ’å
        f.write(f"{'='*70}\n")
        f.write(f"ä¸€ã€æ€§åˆ«éš”ç¦»ç¨‹åº¦æ’åï¼ˆæ ‡å‡†å·®ï¼‰\n")
        f.write(f"{'='*70}\n")
        f.write(f"è¯´æ˜ï¼šæ ‡å‡†å·®è¶Šå¤§ = èŒä¸šæ€§åˆ«åˆ†åŒ–è¶Šæ˜æ˜¾ = æ€§åˆ«éš”ç¦»è¶Šä¸¥é‡\n\n")

        stats_sorted = stats_df.sort_values("std_bias", ascending=False)
        f.write(f"Top 10 æ€§åˆ«éš”ç¦»æœ€æ˜æ˜¾çš„çœä»½:\n")
        for i, (_, row) in enumerate(stats_sorted.head(10).iterrows(), 1):
            f.write(
                f"  {i:2d}. {row['province']:8s} | "
                f"éš”ç¦»æŒ‡æ•°: {row['std_bias']:.4f} | "
                f"å¹³å‡åå‘: {row['mean_bias']:+.4f} | "
                f"åŒºåŸŸ: {row['region']}\n"
            )

        f.write(f"\nTop 10 æ€§åˆ«éš”ç¦»æœ€ä¸æ˜æ˜¾çš„çœä»½:\n")
        for i, (_, row) in enumerate(stats_sorted.tail(10).iloc[::-1].iterrows(), 1):
            f.write(
                f"  {i:2d}. {row['province']:8s} | "
                f"éš”ç¦»æŒ‡æ•°: {row['std_bias']:.4f} | "
                f"å¹³å‡åå‘: {row['mean_bias']:+.4f} | "
                f"åŒºåŸŸ: {row['region']}\n"
            )

        # 2. åœ°ç†åŒºåŸŸåˆ†æ
        f.write(f"\n{'='*70}\n")
        f.write(f"äºŒã€åœ°ç†åŒºåŸŸåˆ†æ\n")
        f.write(f"{'='*70}\n\n")

        region_stats = (
            stats_df.groupby("region")
            .agg(
                {
                    "std_bias": ["mean", "std", "min", "max"],
                    "mean_bias": "mean",
                    "province": "count",
                }
            )
            .round(4)
        )

        region_stats.columns = [
            "å¹³å‡éš”ç¦»",
            "éš”ç¦»æ ‡å‡†å·®",
            "æœ€å°éš”ç¦»",
            "æœ€å¤§éš”ç¦»",
            "å¹³å‡åå‘",
            "çœä»½æ•°",
        ]
        region_stats = region_stats.sort_values("å¹³å‡éš”ç¦»", ascending=False)

        f.write(region_stats.to_string())
        f.write(f"\n\nè§£è¯»ï¼š\n")
        f.write(
            f"  - å¹³å‡éš”ç¦»æœ€é«˜çš„åŒºåŸŸ: {region_stats.index[0]} ({region_stats.iloc[0]['å¹³å‡éš”ç¦»']:.4f})\n"
        )
        f.write(
            f"  - å¹³å‡éš”ç¦»æœ€ä½çš„åŒºåŸŸ: {region_stats.index[-1]} ({region_stats.iloc[-1]['å¹³å‡éš”ç¦»']:.4f})\n"
        )

        # 3. æç«¯æ¡ˆä¾‹åˆ†æ
        f.write(f"\n{'='*70}\n")
        f.write(f"ä¸‰ã€æç«¯æ¡ˆä¾‹åˆ†æ\n")
        f.write(f"{'='*70}\n\n")

        most_male_biased = stats_df.nsmallest(5, "mean_bias")
        most_female_biased = stats_df.nlargest(5, "mean_bias")

        f.write(f"æ•´ä½“æœ€åç”·æ€§çš„çœä»½ (Top 5):\n")
        for i, (_, row) in enumerate(most_male_biased.iterrows(), 1):
            f.write(
                f"  {i}. {row['province']:8s} | å¹³å‡åå‘: {row['mean_bias']:+.4f}\n"
            )

        f.write(f"\næ•´ä½“æœ€åå¥³æ€§çš„çœä»½ (Top 5):\n")
        for i, (_, row) in enumerate(most_female_biased.iterrows(), 1):
            f.write(
                f"  {i}. {row['province']:8s} | å¹³å‡åå‘: {row['mean_bias']:+.4f}\n"
            )

        # 4. ç‰¹å®šèŒä¸šçš„çœä»½å·®å¼‚
        f.write(f"\n{'='*70}\n")
        f.write(f"å››ã€å…¸å‹èŒä¸šçš„çœä»½å·®å¼‚\n")
        f.write(f"{'='*70}\n\n")

        key_occupations = ["æŠ¤å£«", "ç¨‹åºå‘˜", "æ•™å¸ˆ", "åŒ»ç”Ÿ", "CEO"]
        for occ in key_occupations:
            occ_data = occupation_df[occupation_df["occupation"] == occ]
            if len(occ_data) > 0:
                f.write(f"\nã€{occ}ã€‘\n")
                f.write(f"  å…¨å›½å¹³å‡åå‘: {occ_data['bias_score'].mean():+.4f}\n")
                f.write(f"  çœä»½é—´å·®å¼‚ï¼ˆæ ‡å‡†å·®ï¼‰: {occ_data['bias_score'].std():.4f}\n")
                f.write(
                    f"  æœ€åå¥³æ€§: {occ_data.nlargest(3, 'bias_score')['province'].tolist()}\n"
                )
                f.write(
                    f"  æœ€åç”·æ€§: {occ_data.nsmallest(3, 'bias_score')['province'].tolist()}\n"
                )

        # 5. æ•°æ®è´¨é‡è¯´æ˜
        f.write(f"\n{'='*70}\n")
        f.write(f"äº”ã€æ•°æ®è´¨é‡è¯´æ˜\n")
        f.write(f"{'='*70}\n\n")
        f.write(f"  æ€»çœä»½æ•°: {len(stats_df)}\n")
        f.write(f"  æ€»æ–‡æœ¬æ•°: {stats_df['text_count'].sum():,}\n")
        f.write(f"  å¹³å‡æ¯çœä»½æ–‡æœ¬æ•°: {stats_df['text_count'].mean():,.0f}\n")
        f.write(
            f"  æ–‡æœ¬æ•°æœ€å¤šçš„çœä»½: {stats_df.nlargest(1, 'text_count')['province'].values[0]}\n"
        )
        f.write(
            f"  æ–‡æœ¬æ•°æœ€å°‘çš„çœä»½: {stats_df.nsmallest(1, 'text_count')['province'].values[0]}\n"
        )

    print(f"âœ“ åˆ†ææ€»ç»“å·²ä¿å­˜: {report_file}")


def main(year: int, shapefile: str = None):
    """
    è¿è¡Œå¯è§†åŒ–åˆ†æ

    Args:
        year: å¹´ä»½
        shapefile: ä¸­å›½åœ°å›¾shapefileè·¯å¾„ï¼ˆå¯é€‰ï¼‰
                  ä¾‹å¦‚: 'china_map/china_province.shp'
    """
    print(f"\n{'='*70}")
    print(f"ğŸ¨ å¼€å§‹ç”Ÿæˆ {year} å¹´çœä»½æ€§åˆ«-èŒä¸šåå‘å¯è§†åŒ–")
    print(f"{'='*70}\n")

    # åŠ è½½æ•°æ®
    stats_df, occupation_df = load_results(year)
    if stats_df is None or occupation_df is None:
        return

    # 1. ä¸­å›½åœ°å›¾ï¼ˆæ€§åˆ«éš”ç¦»ç¨‹åº¦ï¼‰
    print(f"\nğŸ“ ç”Ÿæˆä¸­å›½åœ°å›¾...")
    plot_china_map_segregation(stats_df, year, shapefile)

    # 2. çœä»½æ’åå›¾
    print(f"\nğŸ“Š ç”Ÿæˆçœä»½æ’åå›¾...")
    plot_province_ranking(stats_df, year)

    # 3. çœä»½èšç±»åˆ†æ
    print(f"\nğŸŒ³ ç”Ÿæˆçœä»½èšç±»åˆ†æ...")
    plot_province_clustering(occupation_df, stats_df, year)

    # 4. çœä»½å¤šç»´åº¦å¯¹æ¯”
    print(f"\nğŸ“ˆ ç”Ÿæˆçœä»½å¯¹æ¯”å›¾...")
    plot_province_comparison(stats_df, year)

    # 5. ç‰¹å®šèŒä¸šçš„çœä»½å·®å¼‚
    print(f"\nğŸ‘” ç”Ÿæˆå…¸å‹èŒä¸šåˆ†æ...")
    key_occupations = ["æŠ¤å£«", "ç¨‹åºå‘˜", "æ•™å¸ˆ", "åŒ»ç”Ÿ", "CEO"]
    for occ in key_occupations:
        if occ in occupation_df["occupation"].values:
            plot_occupation_by_province(occupation_df, occ, year)

    # 6. ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
    print(f"\nğŸ“ ç”Ÿæˆæ€»ç»“æŠ¥å‘Š...")
    generate_summary_report(stats_df, occupation_df, year)

    print(f"\n{'='*70}")
    print(f"âœ… å¯è§†åŒ–å®Œæˆï¼æ‰€æœ‰æ–‡ä»¶å·²ä¿å­˜åˆ°: {OUTPUT_DIR}/")
    print(f"{'='*70}\n")

    print(f"ç”Ÿæˆçš„æ–‡ä»¶åŒ…æ‹¬:")
    print(f"  1. segregation_map_{year}.pdf - ä¸­å›½åœ°å›¾ï¼ˆæ€§åˆ«éš”ç¦»ç¨‹åº¦ï¼‰")
    print(f"  2. segregation_map_regional_{year}.pdf - ä¸­å›½åœ°å›¾ï¼ˆæŒ‰åŒºåŸŸç€è‰²ï¼‰")
    print(f"  3. segregation_ranking_{year}.pdf - çœä»½æ’åå›¾")
    print(f"  4. province_clustering_{year}.pdf - çœä»½èšç±»æ ‘çŠ¶å›¾")
    print(f"  5. province_similarity_{year}.pdf - çœä»½ç›¸ä¼¼åº¦çƒ­åŠ›å›¾")
    print(f"  6. province_comparison_{year}.pdf - çœä»½å¤šç»´åº¦å¯¹æ¯”")
    print(f"  7. occupation_[èŒä¸šå]_{year}.pdf - å„èŒä¸šçš„çœä»½åˆ†æ")
    print(f"  8. visualization_summary_{year}.txt - æ–‡å­—æ€»ç»“æŠ¥å‘Š\n")


if __name__ == "__main__":
    import fire

    fire.Fire(main)
